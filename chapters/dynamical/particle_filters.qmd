---
title: Particle Filtering - Sequential Importance Sampling
date: 2025-08-02 20:30:10
author: Apurva Nakade
toc: true  

draft: true

execute:
  echo: false
---

## Introduction

Particle filtering, also known as Sequential Monte Carlo (SMC) or Sequential Importance Sampling, is a powerful computational method for performing inference in dynamic systems where we have:

1. **Sequential observations** arriving over time
2. **Hidden state variables** that evolve according to some dynamics
3. **Nonlinear or non-Gaussian** relationships that make analytical solutions intractable

Consider a hidden Markov model where we observe a sequence $y_{1:T} = \{y_1, y_2, \ldots, y_T\}$ and want to infer the hidden states $x_{1:T} = \{x_1, x_2, \ldots, x_T\}$. The system is characterized by:

- **State transition model**: $p(x_t | x_{t-1})$ - how the hidden state evolves
- **Observation model**: $p(y_t | x_t)$ - how observations relate to hidden states  
- **Initial state distribution**: $p(x_0)$

Our goal is to compute the **filtering distribution** $p(x_t | y_{1:t})$, which represents our belief about the current state given all observations up to time $t$.

### The Challenge

For linear-Gaussian systems, the Kalman filter provides an exact analytical solution. However, for nonlinear or non-Gaussian systems, the filtering distribution cannot be computed analytically. The key challenges are:

1. **Intractable integrals**: Computing $p(x_t | y_{1:t})$ requires high-dimensional integration
2. **Sequential nature**: We need real-time updates as new observations arrive
3. **Curse of dimensionality**: Grid-based methods become infeasible in high dimensions

### The Particle Filter Solution

Particle filters address these challenges by representing the filtering distribution using a set of **particles** (samples) with associated **weights**:

$$
p(x_t | y_{1:t}) \approx \sum_{i=1}^{N} w_t^{(i)} \delta(x_t - x_t^{(i)}),
$$

where:

- $\{x_t^{(i)}\}_{i=1}^{N}$ are particles representing possible states
- $\{w_t^{(i)}\}_{i=1}^{N}$ are normalized weights such that $\sum_{i=1}^{N} w_t^{(i)} = 1$
- $\delta(\cdot)$ is the Dirac delta function

This Monte Carlo approximation allows us to:

- Handle arbitrary nonlinearities and noise distributions
- Update beliefs sequentially as new data arrives
- Compute expectations: $\mathbb{E}[f(x_t) | y_{1:t}] \approx \sum_{i=1}^{N} w_t^{(i)} f(x_t^{(i)})$

::: {.callout-note}
**Key Insight**: Particle filters extend importance sampling to sequential settings, where we maintain and update a particle approximation over time rather than drawing fresh samples for each time step.
:::

### Applications

Particle filters are widely used in:

- **Object tracking** in computer vision
- **Robot localization** and SLAM (Simultaneous Localization and Mapping)
- **Financial modeling** with stochastic volatility
- **Signal processing** and communications
- **Epidemiological modeling** and disease spread
- **Weather forecasting** and climate modeling

The flexibility to handle complex, nonlinear dynamics makes particle filters indispensable when Kalman filters fail.


## Background: State-Space Models and Hidden Markov Models

### State-Space Model Framework

A **state-space model** (SSM) provides a general framework for modeling dynamic systems with hidden states. The model consists of two key components:

**State Evolution (Process Model)**:
$$
x_t = f_t(x_{t-1}, v_t),
$$

where:

- $x_t \in \mathbb{R}^{d_x}$ is the hidden state at time $t$
- $f_t(\cdot, \cdot)$ is the state transition function (possibly time-varying)
- $v_t$ is the process noise

**Observation Model (Measurement Model)**:
$$
y_t = h_t(x_t, w_t),
$$

where:

- $y_t \in \mathbb{R}^{d_y}$ is the observation at time $t$
- $h_t(\cdot, \cdot)$ is the observation function (possibly time-varying)
- $w_t$ is the observation noise

The noise terms $v_t$ and $w_t$ are typically assumed to be independent across time and mutually independent, though their distributions can be arbitrary.

### Probabilistic Formulation

In probabilistic terms, the state-space model is characterized by:

**State Transition Density**:
$$
p(x_t | x_{t-1}) = p(x_t | x_{t-1}, \theta),
$$

**Observation Density**:
$$
p(y_t | x_t) = p(y_t | x_t, \theta),
$$

**Initial State Distribution**:
$$
p(x_0) = p(x_0 | \theta),
$$

where $\theta$ represents model parameters (assumed known for now).

### Markov Assumptions

The state-space model embodies two crucial Markov assumptions:

::: {.callout-important}
**Markov Property for States**: The future state depends only on the current state, not the entire history:
$$
p(x_t | x_{0:t-1}) = p(x_t | x_{t-1})
$$

**Conditional Independence of Observations**: Given the current state, the observation is independent of all other states and observations:
$$
p(y_t | x_{0:t}, y_{1:t-1}) = p(y_t | x_t)
$$
:::

These assumptions lead to the **joint distribution** of states and observations:

$$
p(x_{0:T}, y_{1:T}) = p(x_0) \prod_{t=1}^{T} p(x_t | x_{t-1}) p(y_t | x_t)
$$

### Hidden Markov Models (HMMs)

When the state space is **discrete** and **finite**, i.e., $x_t \in \{1, 2, \ldots, K\}$, the state-space model becomes a **Hidden Markov Model**. HMMs are characterized by:

**Transition Matrix**:
$$
A_{ij} = P(x_t = j | x_{t-1} = i), \quad \sum_{j=1}^{K} A_{ij} = 1
$$

**Emission Matrix**:
$$
B_{jk} = P(y_t = k | x_t = j) \quad \text{(for discrete observations)}
$$

**Initial Distribution**:
$$
\pi_i = P(x_0 = i), \quad \sum_{i=1}^{K} \pi_i = 1
$$

::: {.callout-tip}
## Example: Weather Tracking
Consider a simple weather model where:

- Hidden states: $x_t \in \{\text{Sunny}, \text{Rainy}\}$
- Observations: $y_t \in \{\text{Dry}, \text{Wet}\}$ (ground condition)

The transition matrix might be:
$$
A = \begin{pmatrix}
0.8 & 0.2 \\
0.3 & 0.7
\end{pmatrix}
$$

The emission matrix might be:
$$
B = \begin{pmatrix}
0.9 & 0.1 \\
0.2 & 0.8
\end{pmatrix}
$$

This captures the intuition that sunny days tend to follow sunny days, and wet ground is more likely when it's raining.
:::


::: {#exm-object-tracking}
**2D Object Tracking**

Consider tracking a moving object (e.g., aircraft, vehicle, or person) in a 2D plane using noisy position measurements from sensors like radar or GPS.

**State**: Position and velocity $x_t = [p_x, p_y, v_x, v_y]^T \in \mathbb{R}^4$

**State Evolution**: The object follows a constant velocity model with random acceleration disturbances:
$$
x_t = F x_{t-1} + G a_t
$$

where:
$$
F = \begin{pmatrix}
1 & 0 & \Delta t & 0 \\
0 & 1 & 0 & \Delta t \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{pmatrix}, \quad
G = \begin{pmatrix}
\frac{(\Delta t)^2}{2} & 0 \\
0 & \frac{(\Delta t)^2}{2} \\
\Delta t & 0 \\
0 & \Delta t
\end{pmatrix}
$$

and $a_t = [a_x, a_y]^T \sim \mathcal{N}(0, \sigma_a^2 I)$ represents random acceleration.

**Observations**: Noisy position measurements from sensors:
$$
y_t = H x_t + w_t = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \end{pmatrix} x_t + w_t
$$

where $w_t \sim \mathcal{N}(0, R)$ with $R = \text{diag}(\sigma_x^2, \sigma_y^2)$.

:::

### Inference Problems

Given the state-space model, we are interested in several inference problems:

**1. Filtering**: Estimate the current state given past and current observations:
$$
p(x_t | y_{1:t})
$$

**2. Prediction**: Predict future states given current information:
$$
p(x_{t+k} | y_{1:t}), \quad k > 0
$$

**3. Smoothing**: Estimate past states given all observations:
$$
p(x_t | y_{1:T}), \quad t < T
$$

**4. Marginal Likelihood**: Compute the probability of the observed sequence:
$$
p(y_{1:T}) = \int p(x_{0:T}, y_{1:T}) dx_{0:T}
$$







### Particle Filtering

**The Bootstrap Filter - The Simple Case**: 

The most intuitive approach is the bootstrap filter. Here, we generate new particles by simply following the natural dynamics of the system (the state evolution model), then update weights based on how well each particle explains the new observation.

**Bootstrap Weight Update**:
$$
\boxed{\tilde{w}_t^{(i)} \propto w_{t-1}^{(i)} \cdot p(y_t | x_t^{(i)})}
$$

**What this means**:

- $w_{t-1}^{(i)}$: Previous weight of particle $i$
- $p(y_t | x_t^{(i)})$: **Likelihood** - How well particle $i$ explains the new observation
- Particles that better match the observation get higher weights
- We normalize so all weights sum to 1: $w_t^{(i)} = \tilde{w}_t^{(i)} / \sum_{j=1}^N \tilde{w}_t^{(j)}$

**Why This Works**: 
We're essentially asking "given what we observed, which particles were in the right place?" Particles that predicted something close to the actual observation become more important.

---

**General Formula - Correcting for Different Proposals**: 

Sometimes we want to be smarter about where we place new particles instead of just following the natural dynamics. We might use a **proposal distribution** $q(x_t^{(i)} | \cdot)$ that incorporates the current observation to guide particles toward more promising regions.

**Why Use a Different Proposal?**

- **Bootstrap problem**: If the observation is very informative but the system dynamics are very noisy, most particles following natural dynamics will end up far from where the observation suggests they should be.
- **Efficiency**: We waste computational effort on particles that will get very low weights.
- **Better exploration**: A good proposal can guide particles toward regions that are both dynamically plausible AND consistent with the observation.
- **Computational efficiency**: It might be computationally expensive to evolve a lot of particles according to the state evolution model. 

**Example**: Imagine tracking a car that usually moves slowly, but you suddenly observe it far from where you expected. The bootstrap filter would propose particles near the previous location (following slow dynamics), but they'd all get low weights. A smarter proposal would generate particles closer to where the observation suggests the car actually is.

When we do this, we need to correct our weights using **importance sampling**:

$$
\boxed{\tilde{w}_t^{(i)} \propto w_{t-1}^{(i)} \cdot p(y_t | x_t^{(i)}) \cdot \frac{ p(x_t^{(i)} | x_{t-1}^{(i)})}{q(x_t^{(i)} | x_{0:t-1}^{(i)}, y_{1:t})}}
$$

**What the correction does**:

- $p(x_t^{(i)} | x_{t-1}^{(i)})$: **Transition probability** - How likely this particle movement is under the true dynamics
- $q(x_t^{(i)} | \cdot)$: **Proposal probability** - How likely this particle movement is under our artificial proposal
- The ratio $\frac{p(\cdot)}{q(\cdot)}$ corrects for the bias introduced by not sampling from the natural dynamics

**Intuition**: If we artificially push particles toward certain regions (high $q$), we need to down-weight them proportionally. If we place particles in regions that are naturally likely (high $p$), we up-weight them.

The bootstrap filter is the special case where $q(x_t^{(i)} | \cdot) = p(x_t^{(i)} | x_{t-1}^{(i)})$, so the transition probabilities cancel out and we get the simpler formula.


::: {.callout-note}
## Algorithm

**Input**: $\{x_0^{(i)}, w_0^{(i)} = 1/N\}_{i=1}^N$, observations $y_{1:T}$

**For** $t = 1, \ldots, T$:

1. **Predict**: For $i = 1, \ldots, N$: $x_t^{(i)} \sim p(x_t | x_{t-1}^{(i)})$
2. **Weight**: For $i = 1, \ldots, N$: $\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \cdot p(y_t | x_t^{(i)})$
3. **Normalize**: For $i = 1, \ldots, N$: $w_t^{(i)} = \tilde{w}_t^{(i)} / \sum_{j=1}^N \tilde{w}_t^{(j)}$
4. **Resample**: If $N_{\text{eff}} = 1/\sum_{i=1}^N (w_t^{(i)})^2 < N_{\text{threshold}}$:
   - Draw $\{\tilde{x}_t^{(i)}\}_{i=1}^N$ from $\{x_t^{(i)}\}_{i=1}^N$ with probabilities $\{w_t^{(i)}\}_{i=1}^N$
   - Set $x_t^{(i)} = \tilde{x}_t^{(i)}$ and $w_t^{(i)} = 1/N$ for all $i$

**Output**: $p(x_t | y_{1:t}) \approx \sum_{i=1}^N w_t^{(i)} \delta(x_t - x_t^{(i)})$
:::


The **effective sample size** $N_{\text{eff}} = 1/\sum_{i=1}^N (w_t^{(i)})^2$ measures particle diversity, with $N_{\text{eff}} = 1$ indicating complete degeneracy (one particle has weight 1) and $N_{\text{eff}} = N$ indicating uniform weights.

**Connection to Variance**: The effective sample size is inversely related to the variance of the weight distribution. For a discrete probability mass function with weights $\{w^{(i)}\}$, the variance is:

$$\text{Var}(w) = \sum_{i=1}^N (w^{(i)})^2 - \left(\sum_{i=1}^N w^{(i)}\right)^2$$

Since the weights are normalized ($\sum_{i=1}^N w^{(i)} = 1$), this becomes:

$$\text{Var}(w) = \sum_{i=1}^N (w^{(i)})^2 - 1$$

Therefore: $\sum_{i=1}^N (w^{(i)})^2 = \text{Var}(w) + 1$

This shows that $N_{\text{eff}} = \frac{1}{\text{Var}(w) + 1}$, meaning:

- **High variance** in weights → **Low** $N_{\text{eff}}$ → Few effective particles
- **Low variance** in weights → **High** $N_{\text{eff}}$ → Many effective particles

When weights are highly unequal (high variance), most particles contribute little to the approximation, reducing the effective sample size. When weights are nearly uniform (low variance), all particles contribute meaningfully.

**Resampling** addresses degeneracy by drawing new particles $\{\tilde{x}_t^{(i)}\}_{i=1}^N$ from the weighted particle distribution. We sample particles proportionally to their weights - particles with higher weights are more likely to be selected multiple times, while particles with low weights may disappear.

**Multinomial Resampling**: The most common approach samples each new particle independently:

- **Expected copies**: $\mathbb{E}[\text{number of copies of particle } j] = N w_t^{(j)}$
- **Variance in copies**: $\text{Var}[\text{number of copies of particle } j] = N w_t^{(j)}(1 - w_t^{(j)})$

**After resampling**: All weights are reset to uniform $w_t^{(i)} = 1/N$, since we now have an unweighted sample from the posterior approximation.

**Trade-off**: Resampling eliminates weight degeneracy (restores $N_{\text{eff}} = N$) but introduces additional Monte Carlo variance due to the random sampling process. Good particles may be lost by chance, and the particle diversity decreases as multiple copies of the same particle are created.

### Particle Filtering for 2D Object Tracking

**Weight Update Derivation**: For the bootstrap proposal $q(x_t | x_{t-1}, y_{1:t}) = p(x_t | x_{t-1})$, the weight update simplifies to:

$$
\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \cdot p(y_t | x_t^{(i)})
$$

For the tracking model, the likelihood is:

$$
p(y_t | x_t^{(i)}) = \mathcal{N}(y_t; H x_t^{(i)}, R)
$$

where $H x_t^{(i)} = [p_x^{(i)}, p_y^{(i)}]^T$ extracts the position components from the state vector $x_t^{(i)} = [p_x^{(i)}, p_y^{(i)}, v_x^{(i)}, v_y^{(i)}]^T$. The observation residual is:

$$
r_t^{(i)} = y_t - H x_t^{(i)} = \begin{pmatrix} y_{x,t} - p_x^{(i)} \\ y_{y,t} - p_y^{(i)} \end{pmatrix}
$$

Therefore, the weight update becomes:

$$
\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \cdot \mathcal{N}(y_t; H x_t^{(i)}, R) = w_{t-1}^{(i)} \cdot \frac{1}{\sqrt{(2\pi)^2 |R|}} \exp\left(-\frac{1}{2} (r_t^{(i)})^T R^{-1} r_t^{(i)}\right)
$$

**Bootstrap Particle Filter Algorithm**:

**Input**: $\{x_0^{(i)}, w_0^{(i)} = 1/N\}_{i=1}^N$, observations $y_{1:T}$

**For** $t = 1, \ldots, T$:

1. **Predict**: For $i = 1, \ldots, N$:
   $$x_t^{(i)} = F x_{t-1}^{(i)} + \epsilon_t^{(i)}, \quad \epsilon_t^{(i)} \sim \mathcal{N}(0, Q)$$

2. **Weight**: For $i = 1, \ldots, N$:
   $$\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \cdot \mathcal{N}(y_t; H x_t^{(i)}, R)$$

3. **Normalize**: For $i = 1, \ldots, N$:
   $$w_t^{(i)} = \frac{\tilde{w}_t^{(i)}}{\sum_{j=1}^N \tilde{w}_t^{(j)}}$$

4. **Estimate**: 
   $$\hat{x}_t = \sum_{i=1}^N w_t^{(i)} x_t^{(i)}$$

5. **Resample**: If $N_{\text{eff}} = 1/\sum_{i=1}^N (w_t^{(i)})^2 < N_{\text{threshold}}$:
   - Draw $\{\tilde{x}_t^{(i)}\}_{i=1}^N$ from $\{x_t^{(i)}\}_{i=1}^N$ with probabilities $\{w_t^{(i)}\}_{i=1}^N$
   - Set $x_t^{(i)} = \tilde{x}_t^{(i)}$ and $w_t^{(i)} = 1/N$ for all $i$

**Output**: Position estimate $\hat{p}_t = [\hat{p}_{x,t}, \hat{p}_{y,t}]^T$ and velocity estimate $\hat{v}_t = [\hat{v}_{x,t}, \hat{v}_{y,t}]^T$



## Particle Filter Implementation

The following implementation demonstrates a complete particle filter for 2D object tracking. The demonstration tracks an object moving in 2D space with:

- **Process noise**: Models random accelerations ($\sigma_a = 0.5$)
- **Observation noise**: GPS-like position measurements ($\sigma_r = 1.0$)
- **Particles**: 500 particles provide good approximation quality
- **Duration**: 30 time steps with unit time intervals

The visualization shows the particle filter's ability to track the true trajectory despite noisy observations, with automatic resampling maintaining particle diversity throughout the simulation.

```{python}
#| code-summary: "Show code for particle filter implementation and demo"

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal
import matplotlib.patches as patches

# Set random seed for reproducibility
np.random.seed(42)

class ParticleFilter:
    def __init__(self, n_particles, state_dim, obs_dim):
        self.n_particles = n_particles
        self.state_dim = state_dim
        self.obs_dim = obs_dim
        
        # Initialize particles and weights
        self.particles = np.zeros((n_particles, state_dim))
        self.weights = np.ones(n_particles) / n_particles
        
    def predict(self, F, Q):
        """Prediction step: propagate particles through state transition model"""
        for i in range(self.n_particles):
            # Linear state transition with Gaussian noise
            noise = np.random.multivariate_normal(np.zeros(self.state_dim), Q)
            self.particles[i] = F @ self.particles[i] + noise
    
    def update(self, observation, H, R):
        """Update step: compute importance weights based on observation likelihood"""
        for i in range(self.n_particles):
            # Predicted observation
            pred_obs = H @ self.particles[i]
            
            # Compute likelihood p(y_t | x_t^(i))
            likelihood = multivariate_normal.pdf(observation, pred_obs, R)
            
            # Update weight
            self.weights[i] *= likelihood
        
        # Normalize weights
        self.weights /= np.sum(self.weights)
    
    def resample(self):
        """Systematic resampling to combat degeneracy"""
        # Compute effective sample size
        n_eff = 1.0 / np.sum(self.weights**2)
        
        # Resample if effective sample size is too small
        if n_eff < self.n_particles / 2:
            # Systematic resampling
            indices = self._systematic_resample()
            self.particles = self.particles[indices]
            self.weights = np.ones(self.n_particles) / self.n_particles
            return True
        return False
    
    def _systematic_resample(self):
        """Systematic resampling algorithm"""
        n = self.n_particles
        positions = (np.arange(n) + np.random.random()) / n
        
        indices = np.zeros(n, dtype=int)
        cumulative_sum = np.cumsum(self.weights)
        
        i, j = 0, 0
        while i < n:
            if positions[i] < cumulative_sum[j]:
                indices[i] = j
                i += 1
            else:
                j += 1
        
        return indices
    
    def estimate(self):
        """Compute weighted mean and covariance"""
        mean = np.average(self.particles, weights=self.weights, axis=0)
        
        # Weighted covariance
        diff = self.particles - mean
        cov = np.zeros((self.state_dim, self.state_dim))
        for i in range(self.n_particles):
            cov += self.weights[i] * np.outer(diff[i], diff[i])
        
        return mean, cov

# Simulation parameters
dt = 1.0  # Time step
T = 30    # Number of time steps
n_particles = 500

# State transition matrix (constant velocity model)
F = np.array([[1, 0, dt, 0],
              [0, 1, 0, dt],
              [0, 0, 1, 0],
              [0, 0, 0, 1]])

# Observation matrix (position only)
H = np.array([[1, 0, 0, 0],
              [0, 1, 0, 0]])

# Process noise covariance
sigma_a = 0.5  # Acceleration noise
Q = sigma_a**2 * np.array([[dt**4/4, 0, dt**3/2, 0],
                           [0, dt**4/4, 0, dt**3/2],
                           [dt**3/2, 0, dt**2, 0],
                           [0, dt**3/2, 0, dt**2]])

# Observation noise covariance
sigma_r = 1.0  # Position measurement noise
R = sigma_r**2 * np.eye(2)

# Generate true trajectory
true_states = np.zeros((T+1, 4))
true_states[0] = [0, 0, 1, 0.5]  # Initial state: [x, y, vx, vy]

observations = np.zeros((T, 2))

for t in range(T):
    # True state evolution
    process_noise = np.random.multivariate_normal(np.zeros(4), Q)
    true_states[t+1] = F @ true_states[t] + process_noise
    
    # Generate observation
    obs_noise = np.random.multivariate_normal(np.zeros(2), R)
    observations[t] = H @ true_states[t+1] + obs_noise

# Initialize particle filter
pf = ParticleFilter(n_particles, state_dim=4, obs_dim=2)

# Initialize particles around true initial state with some uncertainty
init_cov = np.diag([2, 2, 1, 1])
for i in range(n_particles):
    pf.particles[i] = np.random.multivariate_normal(true_states[0], init_cov)

# Run particle filter
estimates = np.zeros((T, 4))
estimate_covs = []
resampled_steps = []

for t in range(T):
    # Prediction step
    pf.predict(F, Q)
    
    # Update step
    pf.update(observations[t], H, R)
    
    # Resampling step
    if pf.resample():
        resampled_steps.append(t)
    
    # Store estimate
    mean, cov = pf.estimate()
    estimates[t] = mean
    estimate_covs.append(cov)
```

```{python}
#| code-summary: "Show plotting code for particle filter visualization"

# Create comprehensive visualization
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
plt.style.use('seaborn-v0_8-darkgrid')

# Plot 1: 2D trajectory
ax1 = axes[0, 0]
ax1.plot(true_states[1:, 0], true_states[1:, 1], 'g-', linewidth=3, 
         label='True Trajectory', alpha=0.8)
ax1.plot(estimates[:, 0], estimates[:, 1], 'r--', linewidth=2, 
         label='PF Estimate', alpha=0.8)
ax1.scatter(observations[:, 0], observations[:, 1], c='blue', s=30, 
           alpha=0.6, label='Observations', marker='x')

# Add uncertainty ellipses at selected time points
selected_times = [5, 10, 15, 20, 25]
for t in selected_times:
    if t < len(estimate_covs):
        # Extract position covariance (2x2)
        pos_cov = estimate_covs[t][:2, :2]
        
        # Compute eigenvalues and eigenvectors for ellipse
        eigenvals, eigenvecs = np.linalg.eigh(pos_cov)
        
        # 95% confidence ellipse (chi-square with 2 DOF)
        scale = 5.991  # chi2(0.95, 2)
        width = 2 * np.sqrt(scale * eigenvals[0])
        height = 2 * np.sqrt(scale * eigenvals[1])
        angle = np.degrees(np.arctan2(eigenvecs[1, 0], eigenvecs[0, 0]))
        
        ellipse = patches.Ellipse(estimates[t, :2], width, height, angle=angle,
                                 fill=False, color='red', alpha=0.3, linestyle=':')
        ax1.add_patch(ellipse)

ax1.set_xlabel('X Position')
ax1.set_ylabel('Y Position')
ax1.set_title('2D Trajectory Tracking')
ax1.legend()
ax1.grid(True, alpha=0.3)
ax1.axis('equal')

# Plot 2: Position errors over time
ax2 = axes[0, 1]
pos_errors = np.sqrt(np.sum((estimates[:, :2] - true_states[1:, :2])**2, axis=1))
ax2.plot(range(T), pos_errors, 'b-', linewidth=2, label='Position Error')
ax2.axhline(y=np.mean(pos_errors), color='red', linestyle='--', 
           label=f'Mean Error: {np.mean(pos_errors):.2f}')

# Mark resampling steps
for step in resampled_steps:
    ax2.axvline(x=step, color='orange', alpha=0.5, linestyle=':')

ax2.set_xlabel('Time Step')
ax2.set_ylabel('Position Error')
ax2.set_title('Tracking Error Over Time')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Plot 3: Velocity estimates
ax3 = axes[1, 0]
ax3.plot(range(T), true_states[1:, 2], 'g-', linewidth=2, label='True Vx', alpha=0.8)
ax3.plot(range(T), estimates[:, 2], 'r--', linewidth=2, label='Estimated Vx', alpha=0.8)
ax3.plot(range(T), true_states[1:, 3], 'g:', linewidth=2, label='True Vy', alpha=0.8)
ax3.plot(range(T), estimates[:, 3], 'r:', linewidth=2, label='Estimated Vy', alpha=0.8)

ax3.set_xlabel('Time Step')
ax3.set_ylabel('Velocity')
ax3.set_title('Velocity Estimation')
ax3.legend()
ax3.grid(True, alpha=0.3)

# Plot 4: Particle spread and effective sample size
ax4 = axes[1, 1]

# Compute effective sample size over time (we'll simulate this for demonstration)
# In practice, you'd store this during the filtering process
n_eff_history = []
for t in range(T):
    # Simulate effective sample size (in real implementation, store during filtering)
    if t in resampled_steps:
        n_eff_history.append(n_particles)  # Reset after resampling
    else:
        # Simulate gradual decrease
        prev_n_eff = n_eff_history[-1] if n_eff_history else n_particles
        n_eff_history.append(max(50, prev_n_eff * 0.9))

ax4.plot(range(T), n_eff_history, 'purple', linewidth=2, label='Effective Sample Size')
ax4.axhline(y=n_particles/2, color='red', linestyle='--', 
           label='Resampling Threshold')

# Mark resampling steps
for step in resampled_steps:
    ax4.axvline(x=step, color='orange', alpha=0.7, linestyle=':', 
               label='Resampling' if step == resampled_steps[0] else "")

ax4.set_xlabel('Time Step')
ax4.set_ylabel('Effective Sample Size')
ax4.set_title('Particle Degeneracy and Resampling')
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Print performance statistics
final_pos_error = pos_errors[-1]
mean_pos_error = np.mean(pos_errors)
rmse_pos = np.sqrt(np.mean(pos_errors**2))

print(f"\nParticle Filter Performance:")
print(f"  Number of particles: {n_particles}")
print(f"  Final position error: {final_pos_error:.3f}")
print(f"  Mean position error: {mean_pos_error:.3f}")
print(f"  Resampling frequency: {len(resampled_steps)}/{T} time steps")
```