---
title: Particle Filtering - Sequential Importance Sampling
date: 2025-08-02 20:30:10
author: Apurva Nakade
toc: true  

draft: true

execute:
  echo: false
---

## Introduction

Particle filtering, also known as Sequential Monte Carlo (SMC) or Sequential Importance Sampling, is a powerful computational method for performing inference in dynamic systems where we have:

1. **Sequential observations** arriving over time
2. **Hidden state variables** that evolve according to some dynamics
3. **Nonlinear or non-Gaussian** relationships that make analytical solutions intractable

Consider a hidden Markov model where we observe a sequence $y_{1:T} = \{y_1, y_2, \ldots, y_T\}$ and want to infer the hidden states $x_{1:T} = \{x_1, x_2, \ldots, x_T\}$. The system is characterized by:

- **State transition model**: $p(x_t | x_{t-1})$ - how the hidden state evolves
- **Observation model**: $p(y_t | x_t)$ - how observations relate to hidden states  
- **Initial state distribution**: $p(x_0)$

Our goal is to compute the **filtering distribution** $p(x_t | y_{1:t})$, which represents our belief about the current state given all observations up to time $t$.

### The Challenge

For linear-Gaussian systems, the Kalman filter provides an exact analytical solution. However, for nonlinear or non-Gaussian systems, the filtering distribution cannot be computed analytically. The key challenges are:

1. **Intractable integrals**: Computing $p(x_t | y_{1:t})$ requires high-dimensional integration
2. **Sequential nature**: We need real-time updates as new observations arrive
3. **Curse of dimensionality**: Grid-based methods become infeasible in high dimensions

### The Particle Filter Solution

Particle filters address these challenges by representing the filtering distribution using a set of **particles** (samples) with associated **weights**:

$$
p(x_t | y_{1:t}) \approx \sum_{i=1}^{N} w_t^{(i)} \delta(x_t - x_t^{(i)}),
$$

where:

- $\{x_t^{(i)}\}_{i=1}^{N}$ are particles representing possible states
- $\{w_t^{(i)}\}_{i=1}^{N}$ are normalized weights such that $\sum_{i=1}^{N} w_t^{(i)} = 1$
- $\delta(\cdot)$ is the Dirac delta function

This Monte Carlo approximation allows us to:

- Handle arbitrary nonlinearities and noise distributions
- Update beliefs sequentially as new data arrives
- Compute expectations: $\mathbb{E}[f(x_t) | y_{1:t}] \approx \sum_{i=1}^{N} w_t^{(i)} f(x_t^{(i)})$

::: {.callout-note}
**Key Insight**: Particle filters extend importance sampling to sequential settings, where we maintain and update a particle approximation over time rather than drawing fresh samples for each time step.
:::

### Applications

Particle filters are widely used in:

- **Object tracking** in computer vision
- **Robot localization** and SLAM (Simultaneous Localization and Mapping)
- **Financial modeling** with stochastic volatility
- **Signal processing** and communications
- **Epidemiological modeling** and disease spread
- **Weather forecasting** and climate modeling

The flexibility to handle complex, nonlinear dynamics makes particle filters indispensable when Kalman filters fail.


## Background: State-Space Models and Hidden Markov Models

### State-Space Model Framework

A **state-space model** (SSM) provides a general framework for modeling dynamic systems with hidden states. The model consists of two key components:

**State Evolution (Process Model)**:
$$
x_t = f_t(x_{t-1}, v_t),
$$

where:

- $x_t \in \mathbb{R}^{d_x}$ is the hidden state at time $t$
- $f_t(\cdot, \cdot)$ is the state transition function (possibly time-varying)
- $v_t$ is the process noise

**Observation Model (Measurement Model)**:
$$
y_t = h_t(x_t, w_t),
$$

where:

- $y_t \in \mathbb{R}^{d_y}$ is the observation at time $t$
- $h_t(\cdot, \cdot)$ is the observation function (possibly time-varying)
- $w_t$ is the observation noise

The noise terms $v_t$ and $w_t$ are typically assumed to be independent across time and mutually independent, though their distributions can be arbitrary.

### Probabilistic Formulation

In probabilistic terms, the state-space model is characterized by:

**State Transition Density**:
$$
p(x_t | x_{t-1}) = p(x_t | x_{t-1}, \theta),
$$

**Observation Density**:
$$
p(y_t | x_t) = p(y_t | x_t, \theta),
$$

**Initial State Distribution**:
$$
p(x_0) = p(x_0 | \theta),
$$

where $\theta$ represents model parameters (assumed known for now).

### Markov Assumptions

The state-space model embodies two crucial Markov assumptions:

::: {.callout-important}
**Markov Property for States**: The future state depends only on the current state, not the entire history:
$$
p(x_t | x_{0:t-1}) = p(x_t | x_{t-1})
$$

**Conditional Independence of Observations**: Given the current state, the observation is independent of all other states and observations:
$$
p(y_t | x_{0:t}, y_{1:t-1}) = p(y_t | x_t)
$$
:::

These assumptions lead to the **joint distribution** of states and observations:

$$
p(x_{0:T}, y_{1:T}) = p(x_0) \prod_{t=1}^{T} p(x_t | x_{t-1}) p(y_t | x_t)
$$

### Hidden Markov Models (HMMs)

When the state space is **discrete** and **finite**, i.e., $x_t \in \{1, 2, \ldots, K\}$, the state-space model becomes a **Hidden Markov Model**. HMMs are characterized by:

**Transition Matrix**:
$$
A_{ij} = P(x_t = j | x_{t-1} = i), \quad \sum_{j=1}^{K} A_{ij} = 1
$$

**Emission Matrix**:
$$
B_{jk} = P(y_t = k | x_t = j) \quad \text{(for discrete observations)}
$$

**Initial Distribution**:
$$
\pi_i = P(x_0 = i), \quad \sum_{i=1}^{K} \pi_i = 1
$$

::: {.callout-tip}
## Example: Weather Tracking
Consider a simple weather model where:

- Hidden states: $x_t \in \{\text{Sunny}, \text{Rainy}\}$
- Observations: $y_t \in \{\text{Dry}, \text{Wet}\}$ (ground condition)

The transition matrix might be:
$$
A = \begin{pmatrix}
0.8 & 0.2 \\
0.3 & 0.7
\end{pmatrix}
$$

The emission matrix might be:
$$
B = \begin{pmatrix}
0.9 & 0.1 \\
0.2 & 0.8
\end{pmatrix}
$$

This captures the intuition that sunny days tend to follow sunny days, and wet ground is more likely when it's raining.
:::


::: {#exm-object-tracking}
**2D Object Tracking**

Consider tracking a moving object (e.g., aircraft, vehicle, or person) in a 2D plane using noisy position measurements from sensors like radar or GPS.

**State**: Position and velocity $x_t = [p_x, p_y, v_x, v_y]^T \in \mathbb{R}^4$

**State Evolution**: The object follows a constant velocity model with random acceleration disturbances:
$$
x_t = F x_{t-1} + G a_t
$$

where:
$$
F = \begin{pmatrix}
1 & 0 & \Delta t & 0 \\
0 & 1 & 0 & \Delta t \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{pmatrix}, \quad
G = \begin{pmatrix}
\frac{(\Delta t)^2}{2} & 0 \\
0 & \frac{(\Delta t)^2}{2} \\
\Delta t & 0 \\
0 & \Delta t
\end{pmatrix}
$$

and $a_t = [a_x, a_y]^T \sim \mathcal{N}(0, \sigma_a^2 I)$ represents random acceleration.

**Observations**: Noisy position measurements from sensors:
$$
y_t = H x_t + w_t = \begin{pmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \end{pmatrix} x_t + w_t
$$

where $w_t \sim \mathcal{N}(0, R)$ with $R = \text{diag}(\sigma_x^2, \sigma_y^2)$.

:::

### Inference Problems

Given the state-space model, we are interested in several inference problems:

**1. Filtering**: Estimate the current state given past and current observations:
$$
p(x_t | y_{1:t})
$$

**2. Prediction**: Predict future states given current information:
$$
p(x_{t+k} | y_{1:t}), \quad k > 0
$$

**3. Smoothing**: Estimate past states given all observations:
$$
p(x_t | y_{1:T}), \quad t < T
$$

**4. Marginal Likelihood**: Compute the probability of the observed sequence:
$$
p(y_{1:T}) = \int p(x_{0:T}, y_{1:T}) dx_{0:T}
$$







### Particle Filtering

**Bayes' Theorem for Filtering**: We derive the filtering update using Bayes' theorem. The joint probability of state and observation factorizes as:

$$
p(x_t, y_t | y_{1:t-1}) = p(y_t | x_t, y_{1:t-1}) p(x_t | y_{1:t-1}) = p(y_t | x_t) p(x_t | y_{1:t-1})
$$

where the second equality uses the conditional independence assumption $y_t \perp y_{1:t-1} | x_t$ (observations are independent given the state). We can also write:

$$
p(x_t, y_t | y_{1:t-1}) = p(x_t | y_t, y_{1:t-1}) p(y_t | y_{1:t-1}) = p(x_t | y_{1:t}) p(y_t | y_{1:t-1})
$$

Equating these expressions gives:

$$
p(y_t | x_t) p(x_t | y_{1:t-1}) = p(x_t | y_{1:t}) p(y_t | y_{1:t-1})
$$

Solving for the posterior $p(x_t | y_{1:t})$ yields **Bayes' theorem**:

$$
p(x_t | y_{1:t}) = \frac{p(y_t | x_t) p(x_t | y_{1:t-1})}{p(y_t | y_{1:t-1})}
$$

where $p(y_t | x_t)$ is the **likelihood**, $p(x_t | y_{1:t-1})$ is the **prior**, and the **marginal likelihood** (evidence) is:

$$
p(y_t | y_{1:t-1}) = \int p(y_t | x_t) p(x_t | y_{1:t-1}) dx_t
$$

The prior for the next time step comes from the **Chapman-Kolmogorov equation**:

$$
p(x_t | y_{1:t-1}) = \int p(x_t | x_{t-1}) p(x_{t-1} | y_{1:t-1}) dx_{t-1}
$$

This **prediction step** propagates the previous posterior through the state transition model $p(x_t | x_{t-1})$.

**Sequential Monte Carlo Approximation**: We maintain a particle approximation of the joint posterior:

$$
p(x_{0:t} | y_{1:t}) \approx \sum_{i=1}^N w_t^{(i)} \delta(x_{0:t} - x_{0:t}^{(i)})
$$

where $\{x_{0:t}^{(i)}\}_{i=1}^N$ are particle trajectories and $\{w_t^{(i)}\}_{i=1}^N$ are normalized importance weights with $\sum_{i=1}^N w_t^{(i)} = 1$.

**Proposal Distribution**: Since we cannot sample directly from the posterior $p(x_{0:t} | y_{1:t})$, we use **importance sampling** with a **proposal distribution** $q(x_{0:t} | y_{1:t})$ from which we can easily sample. The proposal distribution is an auxiliary distribution that we design to be:

1. Easy to sample from: $x_{0:t}^{(i)} \sim q(x_{0:t} | y_{1:t})$
2. Similar to the target posterior $p(x_{0:t} | y_{1:t})$ for efficiency

The proposal typically factors sequentially as:

$$
q(x_{0:t} | y_{1:t}) = q(x_0) \prod_{s=1}^t q(x_s | x_{0:s-1}, y_{1:s})
$$

allowing us to extend existing particle trajectories $x_{0:t-1}^{(i)}$ by sampling $x_t^{(i)} \sim q(x_t | x_{0:t-1}^{(i)}, y_{1:t})$.

**Recursive Weight Update**: The importance weight for the joint trajectory is:

$$
w_t^{(i)} = \frac{p(x_{0:t}^{(i)} | y_{1:t})}{q(x_{0:t}^{(i)} | y_{1:t})}
$$

Using the factorization $p(x_{0:t} | y_{1:t}) = p(x_t | x_{0:t-1}, y_{1:t}) p(x_{0:t-1} | y_{1:t})$ and the Markov property, we have:

$$
p(x_{0:t} | y_{1:t}) = \frac{p(y_t | x_t) p(x_t | x_{t-1}) p(x_{0:t-1} | y_{1:t-1})}{p(y_t | y_{1:t-1})}
$$

For a proposal that factors as $q(x_{0:t} | y_{1:t}) = q(x_t | x_{0:t-1}, y_{1:t}) q(x_{0:t-1} | y_{1:t-1})$, the unnormalized importance weight is:

$$
\tilde{w}_t^{(i)} = \frac{p(x_{0:t}^{(i)} | y_{1:t})}{q(x_{0:t}^{(i)} | y_{1:t})} = \frac{p(y_t | x_t^{(i)}) p(x_t^{(i)} | x_{t-1}^{(i)}) p(x_{0:t-1}^{(i)} | y_{1:t-1})}{p(y_t | y_{1:t-1}) q(x_t^{(i)} | x_{0:t-1}^{(i)}, y_{1:t}) q(x_{0:t-1}^{(i)} | y_{1:t-1})}
$$

Since $p(y_t | y_{1:t-1})$ is constant across particles and $\frac{p(x_{0:t-1}^{(i)} | y_{1:t-1})}{q(x_{0:t-1}^{(i)} | y_{1:t-1})} \propto w_{t-1}^{(i)}$, we obtain the **recursive weight update**:

$$
\boxed{\tilde{w}_t^{(i)} \propto w_{t-1}^{(i)} \cdot \frac{p(y_t | x_t^{(i)}) p(x_t^{(i)} | x_{t-1}^{(i)})}{q(x_t^{(i)} | x_{0:t-1}^{(i)}, y_{1:t})}}
$$

**Bootstrap Filter**: The **bootstrap proposal** is the most common choice, setting the proposal equal to the state transition model:

$$
q(x_t^{(i)} | x_{0:t-1}^{(i)}, y_{1:t}) = p(x_t^{(i)} | x_{t-1}^{(i)})
$$

This choice ignores the current observation $y_t$ when proposing new particles, but has the advantage that the transition density cancels in the weight update:

$$
\boxed{\tilde{w}_t^{(i)} \propto w_{t-1}^{(i)} \cdot \frac{p(y_t | x_t^{(i)}) p(x_t^{(i)} | x_{t-1}^{(i)})}{p(x_t^{(i)} | x_{t-1}^{(i)})} = w_{t-1}^{(i)} \cdot p(y_t | x_t^{(i)})}
$$

The normalized weights are $w_t^{(i)} = \tilde{w}_t^{(i)} / \sum_{j=1}^N \tilde{w}_t^{(j)}$.

**Marginal Filtering Distribution**: The marginal filtering distribution is recovered by:

$$
p(x_t | y_{1:t}) = \int p(x_{0:t} | y_{1:t}) dx_{0:t-1} \approx \sum_{i=1}^N w_t^{(i)} \int \delta(x_{0:t} - x_{0:t}^{(i)}) dx_{0:t-1} = \sum_{i=1}^N w_t^{(i)} \delta(x_t - x_t^{(i)})
$$

**Optimal Proposal**: The proposal that minimizes the variance of importance weights is the **optimal proposal**:

$$
q_{\text{opt}}(x_t | x_{0:t-1}, y_{1:t}) = p(x_t | x_{t-1}, y_t) = \frac{p(y_t | x_t) p(x_t | x_{t-1})}{\int p(y_t | x_t') p(x_t' | x_{t-1}) dx_t'}
$$

This incorporates the current observation $y_t$ into the proposal, giving weights $w_t^{(i)} = \int p(y_t | x_t) p(x_t | x_{t-1}^{(i)}) dx_t$, but requires sampling from $p(x_t | x_{t-1}, y_t)$ and computing the normalizing integral, which are often intractable.

::: {.callout-note}
## Algorithm

**Input**: $\{x_0^{(i)}, w_0^{(i)} = 1/N\}_{i=1}^N$, observations $y_{1:T}$

**For** $t = 1, \ldots, T$:

1. **Predict**: For $i = 1, \ldots, N$: $x_t^{(i)} \sim p(x_t | x_{t-1}^{(i)})$
2. **Weight**: For $i = 1, \ldots, N$: $\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \cdot p(y_t | x_t^{(i)})$
3. **Normalize**: For $i = 1, \ldots, N$: $w_t^{(i)} = \tilde{w}_t^{(i)} / \sum_{j=1}^N \tilde{w}_t^{(j)}$
4. **Resample**: If $N_{\text{eff}} = 1/\sum_{i=1}^N (w_t^{(i)})^2 < N_{\text{threshold}}$:
   - Draw $\{\tilde{x}_t^{(i)}\}_{i=1}^N$ from $\{x_t^{(i)}\}_{i=1}^N$ with probabilities $\{w_t^{(i)}\}_{i=1}^N$
   - Set $x_t^{(i)} = \tilde{x}_t^{(i)}$ and $w_t^{(i)} = 1/N$ for all $i$

**Output**: $p(x_t | y_{1:t}) \approx \sum_{i=1}^N w_t^{(i)} \delta(x_t - x_t^{(i)})$
:::


The **effective sample size** $N_{\text{eff}} = 1/\sum_{i=1}^N (w_t^{(i)})^2$ measures particle diversity, with $N_{\text{eff}} = 1$ indicating complete degeneracy (one particle has weight 1) and $N_{\text{eff}} = N$ indicating uniform weights.

**Resampling** addresses degeneracy by drawing new particles $\{\tilde{x}_t^{(i)}\}_{i=1}^N$ from the discrete distribution $\sum_{j=1}^N w_t^{(j)} \delta(x_t - x_t^{(j)})$. Multinomial resampling gives $\mathbb{E}[\#\{i : \tilde{x}_t^{(i)} = x_t^{(j)}\}] = N w_t^{(j)}$ and $\text{Var}[\#\{i : \tilde{x}_t^{(i)} = x_t^{(j)}\}] = N w_t^{(j)}(1 - w_t^{(j)})$. After resampling, all weights are reset to $1/N$, eliminating weight degeneracy but introducing additional Monte Carlo variance.


### Particle Filtering for 2D Object Tracking

**Weight Update Derivation**: For the bootstrap proposal $q(x_t | x_{t-1}, y_{1:t}) = p(x_t | x_{t-1})$, the weight update simplifies to:

$$
\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \cdot p(y_t | x_t^{(i)})
$$

For the tracking model, the likelihood is:

$$
p(y_t | x_t^{(i)}) = \mathcal{N}(y_t; H x_t^{(i)}, R)
$$

where $H x_t^{(i)} = [p_x^{(i)}, p_y^{(i)}]^T$ extracts the position components from the state vector $x_t^{(i)} = [p_x^{(i)}, p_y^{(i)}, v_x^{(i)}, v_y^{(i)}]^T$. The observation residual is:

$$
r_t^{(i)} = y_t - H x_t^{(i)} = \begin{pmatrix} y_{x,t} - p_x^{(i)} \\ y_{y,t} - p_y^{(i)} \end{pmatrix}
$$

Therefore, the weight update becomes:

$$
\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \cdot \mathcal{N}(y_t; H x_t^{(i)}, R) = w_{t-1}^{(i)} \cdot \frac{1}{\sqrt{(2\pi)^2 |R|}} \exp\left(-\frac{1}{2} (r_t^{(i)})^T R^{-1} r_t^{(i)}\right)
$$

**Bootstrap Particle Filter Algorithm**:

**Input**: $\{x_0^{(i)}, w_0^{(i)} = 1/N\}_{i=1}^N$, observations $y_{1:T}$

**For** $t = 1, \ldots, T$:

1. **Predict**: For $i = 1, \ldots, N$:
   $$x_t^{(i)} = F x_{t-1}^{(i)} + \epsilon_t^{(i)}, \quad \epsilon_t^{(i)} \sim \mathcal{N}(0, Q)$$

2. **Weight**: For $i = 1, \ldots, N$:
   $$\tilde{w}_t^{(i)} = w_{t-1}^{(i)} \cdot \mathcal{N}(y_t; H x_t^{(i)}, R)$$

3. **Normalize**: For $i = 1, \ldots, N$:
   $$w_t^{(i)} = \frac{\tilde{w}_t^{(i)}}{\sum_{j=1}^N \tilde{w}_t^{(j)}}$$

4. **Estimate**: 
   $$\hat{x}_t = \sum_{i=1}^N w_t^{(i)} x_t^{(i)}$$

5. **Resample**: If $N_{\text{eff}} = 1/\sum_{i=1}^N (w_t^{(i)})^2 < N_{\text{threshold}}$:
   - Draw $\{\tilde{x}_t^{(i)}\}_{i=1}^N$ from $\{x_t^{(i)}\}_{i=1}^N$ with probabilities $\{w_t^{(i)}\}_{i=1}^N$
   - Set $x_t^{(i)} = \tilde{x}_t^{(i)}$ and $w_t^{(i)} = 1/N$ for all $i$

**Output**: Position estimate $\hat{p}_t = [\hat{p}_{x,t}, \hat{p}_{y,t}]^T$ and velocity estimate $\hat{v}_t = [\hat{v}_{x,t}, \hat{v}_{y,t}]^T$



## Particle Filter Implementation

The following implementation demonstrates a complete particle filter for 2D object tracking. The demonstration tracks an object moving in 2D space with:

- **Process noise**: Models random accelerations ($\sigma_a = 0.5$)
- **Observation noise**: GPS-like position measurements ($\sigma_r = 1.0$)
- **Particles**: 500 particles provide good approximation quality
- **Duration**: 30 time steps with unit time intervals

The visualization shows the particle filter's ability to track the true trajectory despite noisy observations, with automatic resampling maintaining particle diversity throughout the simulation.

```{python}
#| code-summary: "Show code for particle filter implementation and demo"

import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal
import matplotlib.patches as patches

# Set random seed for reproducibility
np.random.seed(42)

class ParticleFilter:
    def __init__(self, n_particles, state_dim, obs_dim):
        self.n_particles = n_particles
        self.state_dim = state_dim
        self.obs_dim = obs_dim
        
        # Initialize particles and weights
        self.particles = np.zeros((n_particles, state_dim))
        self.weights = np.ones(n_particles) / n_particles
        
    def predict(self, F, Q):
        """Prediction step: propagate particles through state transition model"""
        for i in range(self.n_particles):
            # Linear state transition with Gaussian noise
            noise = np.random.multivariate_normal(np.zeros(self.state_dim), Q)
            self.particles[i] = F @ self.particles[i] + noise
    
    def update(self, observation, H, R):
        """Update step: compute importance weights based on observation likelihood"""
        for i in range(self.n_particles):
            # Predicted observation
            pred_obs = H @ self.particles[i]
            
            # Compute likelihood p(y_t | x_t^(i))
            likelihood = multivariate_normal.pdf(observation, pred_obs, R)
            
            # Update weight
            self.weights[i] *= likelihood
        
        # Normalize weights
        self.weights /= np.sum(self.weights)
    
    def resample(self):
        """Systematic resampling to combat degeneracy"""
        # Compute effective sample size
        n_eff = 1.0 / np.sum(self.weights**2)
        
        # Resample if effective sample size is too small
        if n_eff < self.n_particles / 2:
            # Systematic resampling
            indices = self._systematic_resample()
            self.particles = self.particles[indices]
            self.weights = np.ones(self.n_particles) / self.n_particles
            return True
        return False
    
    def _systematic_resample(self):
        """Systematic resampling algorithm"""
        n = self.n_particles
        positions = (np.arange(n) + np.random.random()) / n
        
        indices = np.zeros(n, dtype=int)
        cumulative_sum = np.cumsum(self.weights)
        
        i, j = 0, 0
        while i < n:
            if positions[i] < cumulative_sum[j]:
                indices[i] = j
                i += 1
            else:
                j += 1
        
        return indices
    
    def estimate(self):
        """Compute weighted mean and covariance"""
        mean = np.average(self.particles, weights=self.weights, axis=0)
        
        # Weighted covariance
        diff = self.particles - mean
        cov = np.zeros((self.state_dim, self.state_dim))
        for i in range(self.n_particles):
            cov += self.weights[i] * np.outer(diff[i], diff[i])
        
        return mean, cov

# Simulation parameters
dt = 1.0  # Time step
T = 30    # Number of time steps
n_particles = 500

# State transition matrix (constant velocity model)
F = np.array([[1, 0, dt, 0],
              [0, 1, 0, dt],
              [0, 0, 1, 0],
              [0, 0, 0, 1]])

# Observation matrix (position only)
H = np.array([[1, 0, 0, 0],
              [0, 1, 0, 0]])

# Process noise covariance
sigma_a = 0.5  # Acceleration noise
Q = sigma_a**2 * np.array([[dt**4/4, 0, dt**3/2, 0],
                           [0, dt**4/4, 0, dt**3/2],
                           [dt**3/2, 0, dt**2, 0],
                           [0, dt**3/2, 0, dt**2]])

# Observation noise covariance
sigma_r = 1.0  # Position measurement noise
R = sigma_r**2 * np.eye(2)

# Generate true trajectory
true_states = np.zeros((T+1, 4))
true_states[0] = [0, 0, 1, 0.5]  # Initial state: [x, y, vx, vy]

observations = np.zeros((T, 2))

for t in range(T):
    # True state evolution
    process_noise = np.random.multivariate_normal(np.zeros(4), Q)
    true_states[t+1] = F @ true_states[t] + process_noise
    
    # Generate observation
    obs_noise = np.random.multivariate_normal(np.zeros(2), R)
    observations[t] = H @ true_states[t+1] + obs_noise

# Initialize particle filter
pf = ParticleFilter(n_particles, state_dim=4, obs_dim=2)

# Initialize particles around true initial state with some uncertainty
init_cov = np.diag([2, 2, 1, 1])
for i in range(n_particles):
    pf.particles[i] = np.random.multivariate_normal(true_states[0], init_cov)

# Run particle filter
estimates = np.zeros((T, 4))
estimate_covs = []
resampled_steps = []

for t in range(T):
    # Prediction step
    pf.predict(F, Q)
    
    # Update step
    pf.update(observations[t], H, R)
    
    # Resampling step
    if pf.resample():
        resampled_steps.append(t)
    
    # Store estimate
    mean, cov = pf.estimate()
    estimates[t] = mean
    estimate_covs.append(cov)

print(f"Particle filter completed. Resampled at {len(resampled_steps)} time steps.")
```

```{python}
#| code-summary: "Show plotting code for particle filter visualization"

# Create comprehensive visualization
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
plt.style.use('seaborn-v0_8-darkgrid')

# Plot 1: 2D trajectory
ax1 = axes[0, 0]
ax1.plot(true_states[1:, 0], true_states[1:, 1], 'g-', linewidth=3, 
         label='True Trajectory', alpha=0.8)
ax1.plot(estimates[:, 0], estimates[:, 1], 'r--', linewidth=2, 
         label='PF Estimate', alpha=0.8)
ax1.scatter(observations[:, 0], observations[:, 1], c='blue', s=30, 
           alpha=0.6, label='Observations', marker='x')

# Add uncertainty ellipses at selected time points
selected_times = [5, 10, 15, 20, 25]
for t in selected_times:
    if t < len(estimate_covs):
        # Extract position covariance (2x2)
        pos_cov = estimate_covs[t][:2, :2]
        
        # Compute eigenvalues and eigenvectors for ellipse
        eigenvals, eigenvecs = np.linalg.eigh(pos_cov)
        
        # 95% confidence ellipse (chi-square with 2 DOF)
        scale = 5.991  # chi2(0.95, 2)
        width = 2 * np.sqrt(scale * eigenvals[0])
        height = 2 * np.sqrt(scale * eigenvals[1])
        angle = np.degrees(np.arctan2(eigenvecs[1, 0], eigenvecs[0, 0]))
        
        ellipse = patches.Ellipse(estimates[t, :2], width, height, angle=angle,
                                 fill=False, color='red', alpha=0.3, linestyle=':')
        ax1.add_patch(ellipse)

ax1.set_xlabel('X Position')
ax1.set_ylabel('Y Position')
ax1.set_title('2D Trajectory Tracking')
ax1.legend()
ax1.grid(True, alpha=0.3)
ax1.axis('equal')

# Plot 2: Position errors over time
ax2 = axes[0, 1]
pos_errors = np.sqrt(np.sum((estimates[:, :2] - true_states[1:, :2])**2, axis=1))
ax2.plot(range(T), pos_errors, 'b-', linewidth=2, label='Position Error')
ax2.axhline(y=np.mean(pos_errors), color='red', linestyle='--', 
           label=f'Mean Error: {np.mean(pos_errors):.2f}')

# Mark resampling steps
for step in resampled_steps:
    ax2.axvline(x=step, color='orange', alpha=0.5, linestyle=':')

ax2.set_xlabel('Time Step')
ax2.set_ylabel('Position Error')
ax2.set_title('Tracking Error Over Time')
ax2.legend()
ax2.grid(True, alpha=0.3)

# Plot 3: Velocity estimates
ax3 = axes[1, 0]
ax3.plot(range(T), true_states[1:, 2], 'g-', linewidth=2, label='True Vx', alpha=0.8)
ax3.plot(range(T), estimates[:, 2], 'r--', linewidth=2, label='Estimated Vx', alpha=0.8)
ax3.plot(range(T), true_states[1:, 3], 'g:', linewidth=2, label='True Vy', alpha=0.8)
ax3.plot(range(T), estimates[:, 3], 'r:', linewidth=2, label='Estimated Vy', alpha=0.8)

ax3.set_xlabel('Time Step')
ax3.set_ylabel('Velocity')
ax3.set_title('Velocity Estimation')
ax3.legend()
ax3.grid(True, alpha=0.3)

# Plot 4: Particle spread and effective sample size
ax4 = axes[1, 1]

# Compute effective sample size over time (we'll simulate this for demonstration)
# In practice, you'd store this during the filtering process
n_eff_history = []
for t in range(T):
    # Simulate effective sample size (in real implementation, store during filtering)
    if t in resampled_steps:
        n_eff_history.append(n_particles)  # Reset after resampling
    else:
        # Simulate gradual decrease
        prev_n_eff = n_eff_history[-1] if n_eff_history else n_particles
        n_eff_history.append(max(50, prev_n_eff * 0.9))

ax4.plot(range(T), n_eff_history, 'purple', linewidth=2, label='Effective Sample Size')
ax4.axhline(y=n_particles/2, color='red', linestyle='--', 
           label='Resampling Threshold')

# Mark resampling steps
for step in resampled_steps:
    ax4.axvline(x=step, color='orange', alpha=0.7, linestyle=':', 
               label='Resampling' if step == resampled_steps[0] else "")

ax4.set_xlabel('Time Step')
ax4.set_ylabel('Effective Sample Size')
ax4.set_title('Particle Degeneracy and Resampling')
ax4.legend()
ax4.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Print performance statistics
final_pos_error = pos_errors[-1]
mean_pos_error = np.mean(pos_errors)
rmse_pos = np.sqrt(np.mean(pos_errors**2))

print(f"\nParticle Filter Performance:")
print(f"  Number of particles: {n_particles}")
print(f"  Final position error: {final_pos_error:.3f}")
print(f"  Mean position error: {mean_pos_error:.3f}")
print(f"  RMSE position error: {rmse_pos:.3f}")
print(f"  Resampling frequency: {len(resampled_steps)}/{T} time steps")
```