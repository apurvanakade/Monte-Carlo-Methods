---
title: "Discrete Distributions"
toc: true  

execute:
  echo: false
---


## Discrete Case

Let's consider a simple example where $X$ is a discrete random variable that takes values $1, 2, 3$ with probabilities $0.2, 0.3, 0.5$ respectively. To sample from this distribution, we can use the following algorithm:

1. Generate a random number $u$ from the uniform distribution $U(0, 1)$.
2. If $u \leq 0.2$, set $X = 1$.
3. If $0.2 < u \leq 0.5$, set $X = 2$.
4. If $0.5 < u \leq 1$, set $X = 3$.
5. Return $X$.

This algorithm can be easily extended to the case where $X$ takes $n$ values. This algorithm can be interpreted as a special case of the inverse transform sampling method described below.

### Binomial Distribution

Let $X$ be a random variable with binomial distribution with parameters $n$ and $p$. The probability mass function of $X$ is given by

\begin{align*}
\mathrm{Binomial}(x) = \binom{n}{x} p^x (1-p)^{n-x}, \quad x = 0, 1, \ldots, n.
\end{align*}

One way to sample from the binomial distribution is to treat it as a discrete distribution and use the above algorithm. However, we can use the Bernoulli distribution to sample from the binomial distribution.

If $Y_1, Y_2, \ldots, Y_n$ are independent random variables with Bernoulli distribution with parameter $p$, then the random variable $X = Y_1 + Y_2 + \ldots + Y_n$ has binomial distribution with parameters $n$ and $p$. This gives us a simple algorithm to sample from the binomial distribution:

1. Generate $n$ random numbers $u_1, u_2, \ldots, u_n$ from the uniform distribution $U(0, 1)$.
2. Set $Y_i = 1$ if $u_i \leq p$ and $Y_i = 0$ otherwise for $i = 1, 2, \ldots, n$.
3. Compute $X = Y_1 + Y_2 + \ldots + Y_n$.
4. Return $X$.

