---
title: Estimating $\pi$
date: 2025-08-04 00:38:57
author: Apurva Nakade
toc: true  
execute:
  echo: false
---

::: {.callout-note icon=false}
## Interactive Demo

Adjust the slider below to see how sample size affects the π estimation:

```{=html}
<div style="margin: 20px 0;">
    <label for="pi-n-slider">Sample Size (N):</label>
    <input type="range" id="pi-n-slider" min="10" max="10000" step="100" value="1000" style="width: 300px;">
    <span id="pi-n-value" style="margin-left: 10px; font-weight: bold;">1,000</span>
</div>

<div id="pi-loading" style="padding: 20px; text-align: center;">
    <p>Loading Python environment...</p>
</div>

<div id="pi-main-content" style="display: none; margin: 20px 0;">
    <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; align-items: start;">
        <div>
            <canvas id="pi-canvas" style="border: 1px solid #ccc;"></canvas>
        </div>
        
        <div>
            <h4 style="margin-top: 0;">Results</h4>
            <table style="width: 100%; border-collapse: collapse;">
                <tr style="border-bottom: 1px solid #ddd;">
                    <td style="padding: 8px;">Sample Size:</td>
                    <td style="padding: 8px; font-weight: bold;" id="pi-stat-n">-</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                    <td style="padding: 8px;">Points Inside:</td>
                    <td style="padding: 8px; font-weight: bold;" id="pi-stat-inside">-</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                    <td style="padding: 8px;">π Estimate:</td>
                    <td style="padding: 8px; font-weight: bold;" id="pi-stat-estimate">-</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                    <td style="padding: 8px;">True π:</td>
                    <td style="padding: 8px; font-weight: bold;" id="pi-stat-true">-</td>
                </tr>
                <tr style="border-bottom: 1px solid #ddd;">
                    <td style="padding: 8px;">Absolute Error:</td>
                    <td style="padding: 8px; font-weight: bold;" id="pi-stat-error">-</td>
                </tr>
                <tr>
                    <td style="padding: 8px;">Standard Error:</td>
                    <td style="padding: 8px; font-weight: bold;" id="pi-stat-stderr">-</td>
                </tr>
            </table>
        </div>
    </div>
</div>

<script>
(function() {
    // Disable RequireJS for Pyodide loading
    var saveDefine = window.define;
    window.define = undefined;
    
    var script = document.createElement('script');
    script.src = 'https://cdn.jsdelivr.net/pyodide/v0.23.4/full/pyodide.js';
    script.onload = function() {
        // Restore RequireJS
        window.define = saveDefine;
        initializePyodideApp();
    };
    script.onerror = function() {
        document.getElementById('pi-loading').innerHTML = '<p style="color: red;">Failed to load Pyodide. Please check your internet connection.</p>';
    };
    document.head.appendChild(script);
})();

async function initializePyodideApp() {
    let pyodide;
    let pyReady = false;
    let updateTimeout;
    let isUpdating = false;

    async function initPyodide() {
        try {
            console.log('Loading Pyodide...');
            pyodide = await loadPyodide();
            
            console.log('Loading packages (this may take a moment)...');
            document.getElementById('pi-loading').innerHTML = '<p>Loading Python packages (numpy, matplotlib)...</p>';
            await pyodide.loadPackage(['numpy', 'matplotlib']);
            await pyodide.loadPackage(['numpy', 'matplotlib']);
            
            console.log('Initializing simulation...');
            document.getElementById('pi-loading').innerHTML = '<p>Initializing simulation...</p>';
            
            // Load computation module
            await pyodide.runPythonAsync(`
import numpy as np

class MonteCarloSimulation:
    def __init__(self, seed=0, radius=1):
        np.random.seed(seed)
        self.radius = radius
    
    def run(self, n_samples):
        x = np.random.uniform(-self.radius, self.radius, n_samples)
        y = np.random.uniform(-self.radius, self.radius, n_samples)
        
        distances = np.sqrt(x**2 + y**2)
        inside_circle = distances <= self.radius
        n_inside = np.sum(inside_circle)
        
        pi_estimate = 4 * n_inside / n_samples
        abs_error = abs(pi_estimate - np.pi)
        std_error = np.sqrt(pi_estimate * (4 - pi_estimate) / n_samples)
        
        return {
            'x': x,
            'y': y,
            'inside_circle': inside_circle,
            'n_samples': n_samples,
            'n_inside': int(n_inside),
            'pi_estimate': float(pi_estimate),
            'abs_error': float(abs_error),
            'std_error': float(std_error),
            'radius': self.radius
        }

simulator = MonteCarloSimulation()
            `);
            
            console.log('Initializing visualizer...');
            // Load visualization module
            await pyodide.runPythonAsync(`
import matplotlib.pyplot as plt
from matplotlib.backends.backend_agg import FigureCanvasAgg

class MonteCarloVisualizer:
    def __init__(self, figsize=(6, 6), dpi=100):
        self.figsize = figsize
        self.dpi = dpi
    
    def render(self, simulation_data):
        x = simulation_data['x']
        y = simulation_data['y']
        inside_circle = simulation_data['inside_circle']
        radius = simulation_data['radius']
        
        fig, ax = plt.subplots(figsize=self.figsize, dpi=self.dpi)
        
        theta = np.linspace(0, 2*np.pi, 100)
        ax.plot(radius*np.cos(theta), radius*np.sin(theta), 'k-', linewidth=2)
        ax.plot([-radius, -radius, radius, radius, -radius], 
                [-radius, radius, radius, -radius, -radius], 
                'k-', linewidth=2)
        
        colors = np.where(inside_circle, 'red', 'blue')
        ax.scatter(x, y, c=colors, s=2, alpha=0.6)
        
        ax.set_xticks([])
        ax.set_yticks([])
        ax.axis('equal')
        ax.grid(True, alpha=0.2)
        
        canvas = FigureCanvasAgg(fig)
        canvas.draw()
        renderer = canvas.get_renderer()
        
        raw_data = renderer.tostring_rgb()
        size = canvas.get_width_height()
        
        im = np.frombuffer(raw_data, dtype=np.uint8)
        im = im.reshape(*reversed(size), 3)
        
        plt.close(fig)
        return im

visualizer = MonteCarloVisualizer()
            `);
            
            console.log('Pyodide ready!');
            pyReady = true;
        } catch (err) {
            console.error('Error initializing Pyodide:', err);
            throw err;
        }
    }

    async function updatePlot(N) {
        if (!pyReady || isUpdating) return null;
        
        isUpdating = true;
        
        try {
            const result = await pyodide.runPythonAsync(`
sim_data = simulator.run(${N})
image = visualizer.render(sim_data)

{
    'image': image,
    'n_inside': sim_data['n_inside'],
    'pi_estimate': sim_data['pi_estimate'],
    'abs_error': sim_data['abs_error'],
    'std_error': sim_data['std_error']
}
            `);
            
            isUpdating = false;
            return result.toJs({ dict_converter: Object.fromEntries });
        } catch (err) {
            console.error('Error generating plot:', err);
            isUpdating = false;
            throw err;
        }
    }

    function renderImageToCanvas(canvas, imageData) {
        const ctx = canvas.getContext('2d');
        
        canvas.width = imageData.length;
        canvas.height = imageData[0].length;
        
        const canvasImageData = ctx.createImageData(canvas.width, canvas.height);
        const pixelData = canvasImageData.data;
        
        let pixelIndex = 0;
        for (let y = 0; y < canvas.height; y++) {
            for (let x = 0; x < canvas.width; x++) {
                pixelData[pixelIndex++] = imageData[x][y][0];
                pixelData[pixelIndex++] = imageData[x][y][1];
                pixelData[pixelIndex++] = imageData[x][y][2];
                pixelData[pixelIndex++] = 255;
            }
        }
        
        ctx.putImageData(canvasImageData, 0, 0);
    }

    function updateStats(stats, N) {
        document.getElementById('pi-stat-n').textContent = N.toLocaleString();
        document.getElementById('pi-stat-inside').textContent = stats.n_inside.toLocaleString();
        document.getElementById('pi-stat-estimate').textContent = stats.pi_estimate.toFixed(6);
        document.getElementById('pi-stat-true').textContent = Math.PI.toFixed(6);
        document.getElementById('pi-stat-error').textContent = stats.abs_error.toFixed(6);
        document.getElementById('pi-stat-stderr').textContent = stats.std_error.toFixed(6);
    }

    const canvas = document.getElementById('pi-canvas');

    function handleSliderChange(e) {
        const N = parseInt(e.target.value);
        document.getElementById('pi-n-value').textContent = N.toLocaleString();
        
        canvas.classList.add('updating');
        
        clearTimeout(updateTimeout);
        updateTimeout = setTimeout(async () => {
            try {
                const data = await updatePlot(N);
                if (data) {
                    renderImageToCanvas(canvas, data.image);
                    updateStats(data, N);
                    canvas.classList.remove('updating');
                }
            } catch (err) {
                console.error('Update failed:', err);
            }
        }, 100);
    }

    async function init() {
        try {
            await initPyodide();
            
            document.getElementById('pi-loading').style.display = 'none';
            document.getElementById('pi-main-content').style.display = 'block';
            
            document.getElementById('pi-n-slider').addEventListener('input', handleSliderChange);
            
            const data = await updatePlot(1000);
            if (data) {
                renderImageToCanvas(canvas, data.image);
                updateStats(data, 1000);
            }
        } catch (err) {
            console.error('Initialization failed:', err);
            document.getElementById('pi-loading').innerHTML = '<p style="color: red;">Error loading Python environment. Please refresh the page.</p>';
        }
    }

    init();
}
</script>
```
:::

The visualization above demonstrates the Monte Carlo simulation in action. As you increase the sample size, the estimate becomes more accurate, though the convergence rate remains $O(1/\sqrt{N})$.

```{python}
#| label: tbl-estimate-pi
#| tbl-cap: "Monte Carlo π estimation results for different sample sizes"
import numpy as np
import pandas as pd

# Set random seed for reproducibility
np.random.seed(0)

def estimate_pi(n_samples, radius=1):
    """Estimate π using Monte Carlo method."""
    # Generate random points in [-r, r] × [-r, r]
    x = np.random.uniform(-radius, radius, n_samples)
    y = np.random.uniform(-radius, radius, n_samples)
    
    # Count points inside circle
    inside_circle = x**2 + y**2 <= radius**2
    n_inside = np.sum(inside_circle)
    
    # Estimate π
    pi_estimate = 4 * n_inside / n_samples
    
    # Calculate errors
    abs_error = abs(pi_estimate - np.pi)
    std_error = np.sqrt(pi_estimate * (4 - pi_estimate) / n_samples)
    
    return {
        'Sample Size': f"{n_samples:,}",
        'Points Inside': f"{n_inside:,}",
        'π Estimate': f"{pi_estimate:.6f}",
        'Absolute Error': f"{abs_error:.6f}",
        'Standard Error': f"{std_error:.6f}"
    }

# Run simulations with different sample sizes
sample_sizes = [100, 1000, 10000, 100000]
results = [estimate_pi(n) for n in sample_sizes]

# Display results table
df = pd.DataFrame(results)
df
```


We begin with a classic Monte Carlo application: estimating the value of $\pi$ using geometric probability. This example illustrates the core principles of Monte Carlo simulation while providing an intuitive geometric interpretation.

Consider a unit circle inscribed in a square with side length 2, both centered at the origin. The circle has radius $r = 1$ and area $A_{\text{circle}} = \pi$, while the square has area $A_{\text{square}} = 4$. The ratio of these areas is $\pi/4$.

::: {.callout-note}
## Geometric Relationships
- **Circle**: radius $r = 1$, area $A_{\text{circle}} = \pi r^2 = \pi$
- **Square**: side length $2r = 2$, area $A_{\text{square}} = (2r)^2 = 4$
- **Area ratio**: $\frac{A_{\text{circle}}}{A_{\text{square}}} = \frac{\pi}{4}$
:::

If we randomly sample points uniformly within the square, the probability that any point falls inside the inscribed circle equals this area ratio. This geometric probability provides our pathway to estimating $\pi$.

To formulate this as a Monte Carlo problem, let $(X, Y)$ be uniformly distributed on $[-1, 1] \times [-1, 1]$ and define the indicator random variable:
$$I(X, Y) = \mathbf{1}_{\{X^2 + Y^2 \leq 1\}} = \begin{cases}
1 & \text{if } X^2 + Y^2 \leq 1 \text{ (inside circle)} \\
0 & \text{if } X^2 + Y^2 > 1 \text{ (outside circle)}
\end{cases}$$

The expected value of this indicator function gives us the desired probability:
$$\mathbb{E}[I(X, Y)] = P(X^2 + Y^2 \leq 1) = \frac{\text{Area of unit circle}}{\text{Area of square}} = \frac{\pi}{4}$$

Therefore $\pi = 4\mathbb{E}[I(X, Y)]$, and given $N$ independent samples $(X_1, Y_1), \ldots, (X_N, Y_N)$, our Monte Carlo estimator is:
$$\hat{\pi}_N = 4 \cdot \frac{1}{N}\sum_{i=1}^{N} I(X_i, Y_i) = \frac{4 \cdot \text{(number of points inside circle)}}{N}$$

## Statistical Properties

This estimator possesses several important statistical properties. First, it is unbiased:
$$\mathbb{E}[\hat{\pi}_N] = 4\mathbb{E}\left[\frac{1}{N}\sum_{i=1}^{N} I_i\right] = 4\mathbb{E}[I] = 4 \cdot \frac{\pi}{4} = \pi$$

Since $I \sim \text{Bernoulli}(\pi/4)$, we can compute the variance. The indicator has variance $\text{Var}(I) = \frac{\pi}{4}(1 - \frac{\pi}{4}) = \frac{\pi(4-\pi)}{16}$, which gives our estimator variance:
$$\text{Var}(\hat{\pi}_N) = 16 \cdot \frac{\text{Var}(I)}{N} = \frac{\pi(4-\pi)}{N}$$

The standard error is therefore $\text{SE}(\hat{\pi}_N) = \sqrt{\frac{\pi(4-\pi)}{N}}$.

::: {.callout-important}
## Convergence Rate
The standard error decreases as $O(1/\sqrt{N})$, which is the typical Monte Carlo convergence rate. To gain one decimal place of accuracy, we need approximately 100 times more samples.
:::

By the Central Limit Theorem, for large $N$ we have the asymptotic distribution:
$$\sqrt{N}(\hat{\pi}_N - \pi) \xrightarrow{d} \mathcal{N}(0, \pi(4-\pi))$$

This provides approximate confidence intervals:
$$\hat{\pi}_N \pm z_{\alpha/2} \sqrt{\frac{\pi(4-\pi)}{N}}$$

::: {.callout-tip}
## Monte Carlo Principle
This example demonstrates the fundamental Monte Carlo approach: reformulate a deterministic problem (computing $\pi$) as the expectation of a random variable, then estimate that expectation using sample averages.
:::