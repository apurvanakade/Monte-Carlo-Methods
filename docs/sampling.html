<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>3&nbsp; Sampling From a Probability Distribution – Monte Carlo Methods</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./accept_reject.html" rel="next">
<link href="./rng.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-1e7bc0a9cbfa8b582ec864d515532ff3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./sampling.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Sampling From a Probability Distribution</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Monte Carlo Methods</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Monte Carlo Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rng.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Random Number Generators</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sampling.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Sampling From a Probability Distribution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./accept_reject.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Rejection Sampling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./SDE.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Stochastic Differential Equations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./markov_chains.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Markov Chains</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./gibbs_2d.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Gibbs 2D</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ising.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Ising Model</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mh.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Metropolis–Hastings Algorithm</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./variance_reduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Variance Reduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mmn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">M/M/n Queue</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./bootstrap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Bootstrap</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./hidden_markov.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Hidden Markov Chains</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#discrete-case" id="toc-discrete-case" class="nav-link active" data-scroll-target="#discrete-case"><span class="header-section-number">3.1</span> Discrete Case</a>
  <ul class="collapse">
  <li><a href="#binomial-distribution" id="toc-binomial-distribution" class="nav-link" data-scroll-target="#binomial-distribution"><span class="header-section-number">3.1.1</span> Binomial Distribution</a></li>
  </ul></li>
  <li><a href="#inverse-transform-sampling" id="toc-inverse-transform-sampling" class="nav-link" data-scroll-target="#inverse-transform-sampling"><span class="header-section-number">3.2</span> Inverse Transform Sampling</a>
  <ul class="collapse">
  <li><a href="#exponential-distribution" id="toc-exponential-distribution" class="nav-link" data-scroll-target="#exponential-distribution"><span class="header-section-number">3.2.1</span> Exponential Distribution</a></li>
  <li><a href="#weibull-distribution" id="toc-weibull-distribution" class="nav-link" data-scroll-target="#weibull-distribution"><span class="header-section-number">3.2.2</span> Weibull Distribution</a></li>
  <li><a href="#triangular-distribution" id="toc-triangular-distribution" class="nav-link" data-scroll-target="#triangular-distribution"><span class="header-section-number">3.2.3</span> Triangular Distribution</a></li>
  <li><a href="#normal-distribution" id="toc-normal-distribution" class="nav-link" data-scroll-target="#normal-distribution"><span class="header-section-number">3.2.4</span> Normal Distribution</a></li>
  <li><a href="#poisson-distribution" id="toc-poisson-distribution" class="nav-link" data-scroll-target="#poisson-distribution"><span class="header-section-number">3.2.5</span> Poisson Distribution</a></li>
  </ul></li>
  <li><a href="#beta-distribution" id="toc-beta-distribution" class="nav-link" data-scroll-target="#beta-distribution"><span class="header-section-number">3.3</span> Beta Distribution</a></li>
  <li><a href="#mixture-distributions" id="toc-mixture-distributions" class="nav-link" data-scroll-target="#mixture-distributions"><span class="header-section-number">3.4</span> Mixture Distributions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Sampling From a Probability Distribution</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In this module, we will discuss how to sample from a probability distribution. Sampling from a probability distribution is a fundamental problem in statistics and machine learning. It is used in various applications like Monte Carlo methods, Bayesian inference, and reinforcement learning.</p>
<p>We’ll use this week to review many of the standard probability distributions and how to sample from them. We’ll also discuss the concept of the cumulative distribution function (CDF) and how it can be used to sample from a probability distribution using the inverse transform sampling method.</p>
<p>From now on, we’ll assume that we have a reliable way to generate random numbers from the uniform distribution <span class="math inline">\(U(0, 1)\)</span>.</p>
<p>To understand what it means to sample from a probability distribution, let’s consider a simple example. Let <span class="math inline">\(X\)</span> be a discrete random variable that takes values <span class="math inline">\(1, 2, \ldots, n\)</span> with probabilities <span class="math inline">\(p_1, p_2, \ldots, p_n\)</span>. To sample from this distribution, we want to generate a random variable <span class="math inline">\(X\)</span> such that <span class="math inline">\(\mathbb{P}(X = i) = p_i\)</span> for all <span class="math inline">\(i = 1, 2, \ldots, n\)</span> i.e.&nbsp;we want to select a random integer <span class="math inline">\(i\)</span> with probability <span class="math inline">\(p_i\)</span>. If we generate enough samples <span class="math inline">\(x_1, x_2, \ldots, x_N\)</span> from this distribution, then the fraction of samples that are equal to <span class="math inline">\(i\)</span> will be approximately equal to <span class="math inline">\(p_i\)</span> for large <span class="math inline">\(N\)</span>.</p>
<section id="discrete-case" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="discrete-case"><span class="header-section-number">3.1</span> Discrete Case</h2>
<p>Let’s consider a simple example where <span class="math inline">\(X\)</span> is a discrete random variable that takes values <span class="math inline">\(1, 2, 3\)</span> with probabilities <span class="math inline">\(0.2, 0.3, 0.5\)</span> respectively. To sample from this distribution, we can use the following algorithm:</p>
<ol type="1">
<li>Generate a random number <span class="math inline">\(u\)</span> from the uniform distribution <span class="math inline">\(U(0, 1)\)</span>.</li>
<li>If <span class="math inline">\(u \leq 0.2\)</span>, set <span class="math inline">\(X = 1\)</span>.</li>
<li>If <span class="math inline">\(0.2 &lt; u \leq 0.5\)</span>, set <span class="math inline">\(X = 2\)</span>.</li>
<li>If <span class="math inline">\(0.5 &lt; u \leq 1\)</span>, set <span class="math inline">\(X = 3\)</span>.</li>
<li>Return <span class="math inline">\(X\)</span>.</li>
</ol>
<p>This algorithm can be easily extended to the case where <span class="math inline">\(X\)</span> takes <span class="math inline">\(n\)</span> values. This algorithm can be interpreted as a special case of the inverse transform sampling method described below.</p>
<section id="binomial-distribution" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="binomial-distribution"><span class="header-section-number">3.1.1</span> Binomial Distribution</h3>
<p>Let <span class="math inline">\(X\)</span> be a random variable with binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>. The probability mass function of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
\mathrm{Binomial}(x) = \binom{n}{x} p^x (1-p)^{n-x}, \quad x = 0, 1, \ldots, n.
\end{align*}\]</span></p>
<p>One way to sample from the binomial distribution is to treat it as a discrete distribution and use the above algorithm. However, we can use the Bernoulli distribution to sample from the binomial distribution.</p>
<p>If <span class="math inline">\(Y_1, Y_2, \ldots, Y_n\)</span> are independent random variables with Bernoulli distribution with parameter <span class="math inline">\(p\)</span>, then the random variable <span class="math inline">\(X = Y_1 + Y_2 + \ldots + Y_n\)</span> has binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>. This gives us a simple algorithm to sample from the binomial distribution:</p>
<ol type="1">
<li>Generate <span class="math inline">\(n\)</span> random numbers <span class="math inline">\(u_1, u_2, \ldots, u_n\)</span> from the uniform distribution <span class="math inline">\(U(0, 1)\)</span>.</li>
<li>Set <span class="math inline">\(Y_i = 1\)</span> if <span class="math inline">\(u_i \leq p\)</span> and <span class="math inline">\(Y_i = 0\)</span> otherwise for <span class="math inline">\(i = 1, 2, \ldots, n\)</span>.</li>
<li>Compute <span class="math inline">\(X = Y_1 + Y_2 + \ldots + Y_n\)</span>.</li>
<li>Return <span class="math inline">\(X\)</span>.</li>
</ol>
</section>
</section>
<section id="inverse-transform-sampling" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="inverse-transform-sampling"><span class="header-section-number">3.2</span> Inverse Transform Sampling</h2>
<p>Consider a continuous random variable <span class="math inline">\(X\)</span> with probability density function <span class="math inline">\(f(x)\)</span>. Let <span class="math inline">\(U\)</span> be a random variable with uniform distribution <span class="math inline">\(U(0, 1)\)</span>.</p>
<div id="thm-inverse-transform-sampling" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.1</strong></span> <strong>(Inverse Transform Sampling)</strong>: Let <span class="math inline">\(F(x)\)</span> be the cumulative distribution function of <span class="math inline">\(X\)</span>. If <span class="math inline">\(F(x)\)</span> is strictly increasing and continuous, then the random variable <span class="math inline">\(Y = F^{-1}(U)\)</span> has the same distribution as <span class="math inline">\(X\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">\(F(x)\)</span> be the cumulative distribution function of <span class="math inline">\(X\)</span>. The cumulative distribution function of <span class="math inline">\(U\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}(U \leq u) &amp;= u.
\end{align*}\]</span></p>
<p>Since <span class="math inline">\(F(x)\)</span> is strictly increasing and continuous, it has an inverse <span class="math inline">\(F^{-1}(u)\)</span>.</p>
<p>The cumulative distribution function of <span class="math inline">\(Y = F^{-1}(U)\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}(Y \leq y) &amp;= \mathbb{P}(F^{-1}(U) \leq y) \\
&amp;= \mathbb{P}(U \leq F(y)) \\
&amp;= F(y).
\end{align*}\]</span></p>
<p>Thus, <span class="math inline">\(Y\)</span> has the same distribution as <span class="math inline">\(X\)</span>. <span class="math inline">\(\blacksquare\)</span></p>
<p>The inverse transform sampling method can be used to sample from any probability distribution <span class="math inline">\(X\)</span> for which we can compute the cumulative distribution function <span class="math inline">\(F(x)\)</span> and its inverse <span class="math inline">\(F^{-1}(u)\)</span>. The algorithm to sample from a probability distribution using the inverse transform sampling method is as follows:</p>
<ol type="1">
<li>Generate a random number <span class="math inline">\(u\)</span> from the uniform distribution <span class="math inline">\(U(0, 1)\)</span>.</li>
<li>Compute <span class="math inline">\(x = F^{-1}(u)\)</span>.</li>
<li>Return <span class="math inline">\(x\)</span>.</li>
</ol>
<p>Even when <span class="math inline">\(F(x)\)</span> is not strictly increasing, we can still use the inverse transform sampling method by using the generalized inverse of <span class="math inline">\(F(x)\)</span>. The generalized inverse of <span class="math inline">\(F(x)\)</span> is defined as</p>
<p><span class="math display">\[\begin{align*}
F^{-1}(u) = \inf\{x : F(x) \geq u\}.
\end{align*}\]</span></p>
<p>You can think of <span class="math inline">\(\inf\)</span> as <span class="math inline">\(\min\)</span> for simplicity.</p>
</div>
<section id="exponential-distribution" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="exponential-distribution"><span class="header-section-number">3.2.1</span> Exponential Distribution</h3>
<p>Let <span class="math inline">\(X\)</span> be a random variable with exponential distribution with rate parameter <span class="math inline">\(\lambda &gt; 0\)</span>. The probability density function of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
\mathrm{Exp}(\lambda) = \lambda e^{-\lambda x}, \quad x \geq 0.
\end{align*}\]</span></p>
<p>The cumulative distribution function of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
F(x) = 1 - e^{-\lambda x}, \quad x \geq 0.
\end{align*}\]</span></p>
<p>The inverse of the cumulative distribution function is given by</p>
<p><span class="math display">\[\begin{align*}
F^{-1}(u) = -\frac{1}{\lambda} \log(1 - u).
\end{align*}\]</span></p>
<p>Hence, the inverse transform sampling method can be used to sample from the exponential distribution.</p>
</section>
<section id="weibull-distribution" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="weibull-distribution"><span class="header-section-number">3.2.2</span> Weibull Distribution</h3>
<p>The Weibull distribution is a generalization of the exponential distribution. Let <span class="math inline">\(X\)</span> be a random variable with Weibull distribution with shape parameter <span class="math inline">\(k &gt; 0\)</span> and scale parameter <span class="math inline">\(\lambda &gt; 0\)</span>. The probability density function of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
f(x) = \frac{k}{\lambda} \left(\frac{x}{\lambda}\right)^{k-1} e^{-(x/\lambda)^k}, \quad x \geq 0.
\end{align*}\]</span></p>
<p>The inverse transform sampling method can be used to sample from the Weibull distribution.</p>
</section>
<section id="triangular-distribution" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="triangular-distribution"><span class="header-section-number">3.2.3</span> Triangular Distribution</h3>
<p>Let <span class="math inline">\(X\)</span> be a random variable with triangular distribution supported over the interval <span class="math inline">\([a,b]\)</span> with maximum value at <span class="math inline">\(c \in [a,b]\)</span>. We can use the inverse transform sampling method to sample from the triangular distribution.</p>
<div id="bec92fac" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="sampling_files/figure-html/cell-2-output-1.png" width="523" height="376" class="figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="normal-distribution" class="level3" data-number="3.2.4">
<h3 data-number="3.2.4" class="anchored" data-anchor-id="normal-distribution"><span class="header-section-number">3.2.4</span> Normal Distribution</h3>
<p>The standard normal distribution with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(1\)</span> is given has the probability density function</p>
<p><span class="math display">\[\begin{align*}
N(0, 1) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2}.
\end{align*}\]</span></p>
<p>It is not possible to sample from the normal distribution using the inverse transform sampling method because the cumulative distribution function of the normal distribution does not have a closed-form inverse. However, there are other methods to sample from the normal distribution. One such method is the Box-Muller transform. The Box-Muller transform is based on the following idea. Consider a 2D random variable <span class="math inline">\((X, Y)\)</span> with standard normal distribution. The joint probability density function of <span class="math inline">\((X, Y)\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
f(x, y) = \frac{1}{2\pi} e^{-(x^2 + y^2)/2}, \quad -\infty &lt; x, y &lt; \infty.
\end{align*}\]</span></p>
<p>Let <span class="math inline">\(R = \sqrt{X^2 + Y^2}\)</span> and <span class="math inline">\(\Theta = \arctan(Y/X)\)</span> be the polar coordinates of <span class="math inline">\((X, Y)\)</span>. Then notice that <span class="math inline">\(\theta\)</span> is uniformly distributed in <span class="math inline">\([0, 2\pi]\)</span>. We can calculate the cdf of <span class="math inline">\(R\)</span> as follows:</p>
<p><span class="math display">\[\begin{align*}
\mathbb{P}(R \leq r) &amp;= \mathbb{P}(X^2 + Y^2 \leq r^2) \\
&amp;= \int_{x^2 + y^2 \leq r^2} f(x, y) \, dx \, dy \\
&amp;= \int_{x^2 + y^2 \leq r^2} e^{-(x^2 + y^2)/2} \, dx \, dy \\
&amp;= \int_{0}^{2\pi} \int_{0}^{r} \frac{1}{2\pi} e^{-r^2/2} r \, dr \, d\theta \\
&amp;= 1 - e^{-r^2/2}.
\end{align*}\]</span></p>
<p>We can invert this to get the inverse cdf of <span class="math inline">\(R\)</span>:</p>
<p><span class="math display">\[\begin{align*}
F_R^{-1}(u) = \sqrt{-2 \log(1 - u)}.
\end{align*}\]</span></p>
<p>We can summarize the above discussion in the following theorem.</p>
<div id="thm-box-muller-transform" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.2</strong></span> <strong>(Box-Muller Transform)</strong>: Let <span class="math inline">\(U_1, U_2\)</span> be independent random variables with uniform distribution <span class="math inline">\(U(0, 1)\)</span>. Let <span class="math inline">\(R = \sqrt{-2 \log U_1}\)</span> and <span class="math inline">\(\Theta = 2\pi U_2\)</span>. Then, the random variables <span class="math inline">\(X = R \cos(\Theta)\)</span> and <span class="math inline">\(Y = R \sin(\Theta)\)</span> are independent and have standard normal distribution.</p>
</div>
<p>Note that we are using <span class="math inline">\(U_1\)</span> instead of <span class="math inline">\(1-U_1\)</span> in the formula for <span class="math inline">\(R\)</span>. This is because <span class="math inline">\(1-U_1\)</span> is also uniformly distributed in <span class="math inline">\([0, 1]\)</span>.</p>
<p>This gives us the following algorithm to sample from the normal distribution:</p>
<ol type="1">
<li>Generate two random numbers <span class="math inline">\(u_1, u_2\)</span> from the uniform distribution <span class="math inline">\(U(0, 1)\)</span>.</li>
<li>Compute <span class="math inline">\(R = \sqrt{-2 \log u_1}\)</span> and <span class="math inline">\(\Theta = 2\pi u_2\)</span>.</li>
<li>Compute <span class="math inline">\(X = R \cos(\Theta)\)</span> and <span class="math inline">\(Y = R \sin(\Theta)\)</span>.</li>
<li>Return <span class="math inline">\(X\)</span> (or <span class="math inline">\(Y\)</span>).</li>
</ol>
</section>
<section id="poisson-distribution" class="level3" data-number="3.2.5">
<h3 data-number="3.2.5" class="anchored" data-anchor-id="poisson-distribution"><span class="header-section-number">3.2.5</span> Poisson Distribution</h3>
<p>The Poisson distribution with parameter <span class="math inline">\(\lambda &gt; 0\)</span> is a discrete distribution that models the number of events occurring in a fixed interval of time or space, where <span class="math inline">\(\lambda\)</span> is the average rate of events. In unit time <span class="math inline">\(T\)</span>, the expected number of events is <span class="math inline">\(\lambda T\)</span>. The probability mass function of the Poisson distribution is given by</p>
<p><span class="math display">\[\begin{align*}
\mathrm{Pois}(n) = \frac{e^{-\lambda} \lambda^n}{n!}, \quad n \in \mathbb{N}.
\end{align*}\]</span></p>
<p>The pmf of the Poisson distribution measures the probability of observing <span class="math inline">\(n\)</span> events in time <span class="math inline">\(T\)</span>.</p>
<section id="relation-between-poisson-and-binomial-distribution" class="level4" data-number="3.2.5.1">
<h4 data-number="3.2.5.1" class="anchored" data-anchor-id="relation-between-poisson-and-binomial-distribution"><span class="header-section-number">3.2.5.1</span> Relation between Poisson and Binomial Distribution</h4>
<p>The Poisson distribution can be approximated by the binomial distribution when the number of trials <span class="math inline">\(n\)</span> is large and the probability of success <span class="math inline">\(p\)</span> is small. Let <span class="math inline">\(X\)</span> be a random variable with binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>. As <span class="math inline">\(n \to \infty\)</span> and <span class="math inline">\(p \to 0\)</span> such that <span class="math inline">\(\lambda = np\)</span> remains constant, the pmf of <span class="math inline">\(X\)</span> converges to the pmf of the Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>. This gives us a simple algorithm to sample from the Poisson distribution:</p>
<ol type="1">
<li>Set <span class="math inline">\(X = 0\)</span>.</li>
<li>Choose <span class="math inline">\(n\)</span> be a large integer (something like <span class="math inline">\(n &gt; 10\lambda\)</span>).</li>
<li>Set <span class="math inline">\(p = \lambda/n\)</span>.</li>
<li>Generate a <span class="math inline">\(X\)</span> according to the binomial distribution with parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>.</li>
</ol>
<p>This is a fast method to sample from the Binomial approximation to the Poisson distribution and is good when <span class="math inline">\(\lambda\)</span> is small. For large <span class="math inline">\(\lambda\)</span>, the method described below is more efficient as the number of trials <span class="math inline">\(n\)</span> required for the binomial distribution to approximate the Poisson distribution becomes very large.</p>
</section>
<section id="relation-between-poisson-and-exponential-distribution" class="level4" data-number="3.2.5.2">
<h4 data-number="3.2.5.2" class="anchored" data-anchor-id="relation-between-poisson-and-exponential-distribution"><span class="header-section-number">3.2.5.2</span> Relation between Poisson and Exponential Distribution</h4>
<p>We exploit the relation between the Poisson distribution and the exponential distribution to sample from the Poisson distribution. When events occur at a constant rate <span class="math inline">\(\lambda\)</span>, the time between events follows an exponential distribution with rate parameter <span class="math inline">\(\lambda\)</span>. More precisely,</p>
<div id="thm-poisson-exponential" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.3</strong></span> <strong>(Inter-arrival Times)</strong>:</p>
<p>Let <span class="math inline">\(X_1, X_2, \ldots\)</span> be independent random variables with exponential distribution with rate parameter <span class="math inline">\(\lambda\)</span>. Define</p>
<p><span class="math display">\[\begin{align*}
N = \max \left\{ n : X_1 + X_2 + \dots + X_n \le 1 \right\}.
\end{align*}\]</span></p>
<p>Then, <span class="math inline">\(N\)</span> has Poisson distribution with parameter <span class="math inline">\(\lambda\)</span>.</p>
</div>
<p>The proof of this requires us to understand the relation between exponential and gamma distributions. We will skip the proof for now. The Poisson-Exponential connection gives us a simple algorithm to sample from the Poisson distribution:</p>
<ol type="1">
<li>Set <span class="math inline">\(S = 0\)</span> and <span class="math inline">\(N = 0\)</span>.</li>
<li>While True:
<ol type="1">
<li>Generate a random number <span class="math inline">\(x \sim \mathrm{Exp}(\lambda)\)</span>.</li>
<li>Set <span class="math inline">\(S = S + x\)</span>.</li>
<li>If <span class="math inline">\(S &gt; 1\)</span>, return <span class="math inline">\(N\)</span>.</li>
<li>Else, set <span class="math inline">\(N = N + 1\)</span>.</li>
</ol></li>
</ol>
</section>
</section>
</section>
<section id="beta-distribution" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="beta-distribution"><span class="header-section-number">3.3</span> Beta Distribution</h2>
<p>The Beta distribution is a continuous distribution defined on the interval <span class="math inline">\([0, 1]\)</span>. Let <span class="math inline">\(X\)</span> be a random variable with Beta distribution with parameters <span class="math inline">\(\alpha &gt; 0\)</span> and <span class="math inline">\(\beta &gt; 0\)</span>. The probability density function of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
f(x) = cx^{\alpha-1} (1-x)^{\beta-1}, \quad 0 \leq x \leq 1,
\end{align*}\]</span></p>
<p>where <span class="math inline">\(c= \frac{(\alpha + \beta - 1)!}{(\alpha-1)!(\beta-1)!}\)</span> is the normalizing constant. (Note that when <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are not integers, we use <span class="math inline">\(\Gamma\)</span> function to as a generalization of the factorial function.)</p>
<p>This is a simple function supported over the interval <span class="math inline">\([0, 1]\)</span>. The Beta distribution is used as a prior distribution in Bayesian statistics. When <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are non-zero, the cdf of the Beta distribution does not have a closed-form expression. However, we can use the inverse transform sampling method to sample from the Beta distribution. Instead, we can use the Beta-Order Statistics connection to sample from the Beta distribution.</p>
<div id="def-order-statistics" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 3.1</strong></span> <strong>(Order Statistics)</strong>: Let <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> be independent and identically distributed random variables. The <span class="math inline">\(k\)</span>-th order statistic, denoted <span class="math inline">\(X_{(k)}\)</span>, is the <span class="math inline">\(k\)</span>-th smallest value among <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span>.</p>
</div>
<div id="thm-beta-order-statistics" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3.4</strong></span> <strong>(Beta-Order Statistics)</strong>: Let <span class="math inline">\(U_1, U_2, \ldots, U_n\)</span> be independent random variables with uniform distribution <span class="math inline">\(U(0, 1)\)</span>. Then the random variable <span class="math inline">\(X = U_{(k)}\)</span> has Beta distribution with parameters <span class="math inline">\(\alpha = k\)</span> and <span class="math inline">\(\beta = n - k + 1\)</span>.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>We’ll work out a partial proof of the theorem. Let <span class="math inline">\(X = U_{(k)}\)</span>. The cumulative distribution function of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
F(x)
&amp;= \mathbb{P}(U_{(k)} \leq x) \\
&amp;= \mathbb{P}( \text{at least } k \text{ variables among } U_1, U_2, \ldots, U_n \text{ are less than } x)  \\
&amp;= \sum_{i=k}^{n} \binom{n}{i} x^i (1-x)^{n-i}.
\end{align*}\]</span></p>
<p>We differentiate both sides to get the probability density function of <span class="math inline">\(X\)</span>:</p>
<p><span class="math display">\[\begin{align*}
f(x) &amp;= \frac{d}{dx} F(x) \\
&amp;= \sum_{i=k}^{n} \binom{n}{i} \frac{d}{dx}x^i (1-x)^{n-i} \\
&amp;= \sum_{i=k}^{n} \binom{n}{i} i x^{i-1} (1-x)^{n-i} - \binom{n}{i} (n-i) x^i (1-x)^{n-i-1}.
\end{align*}\]</span></p>
<p>The rest of the proof involves checking that the higher terms in the alternating sum cancel out and only the first term with <span class="math inline">\(i = k\)</span> remains. <span class="math inline">\(\blacksquare\)</span></p>
</div>
<p>This theorem gives us a simple algorithm to sample from the Beta distribution:</p>
<ol type="1">
<li>Generate <span class="math inline">\(n\)</span> random numbers <span class="math inline">\(u_1, u_2, \ldots, u_n\)</span> from the uniform distribution <span class="math inline">\(U(0, 1)\)</span>.</li>
<li>Sort the numbers in increasing order <span class="math inline">\(u_{(1)} \leq u_{(2)} \leq \ldots \leq u_{(n)}\)</span>.</li>
<li>Return <span class="math inline">\(u_{(k)}\)</span>.</li>
</ol>
</section>
<section id="mixture-distributions" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="mixture-distributions"><span class="header-section-number">3.4</span> Mixture Distributions</h2>
<p>A mixture distribution is a probability distribution that is formed by taking a weighted sum of two or more probability distributions. Let <span class="math inline">\(X\)</span> be a random variable that is a mixture of distributions <span class="math inline">\(f_1(x), f_2(x), \ldots, f_n(x)\)</span> with weights <span class="math inline">\(w_1, w_2, \ldots, w_n\)</span>. The probability density function of <span class="math inline">\(X\)</span> is given by</p>
<p><span class="math display">\[\begin{align*}
f(x) = w_1 f_1(x) + w_2 f_2(x) + \ldots + w_n f_n(x).
\end{align*}\]</span></p>
<p>Mixture distributions are used to model complex distributions that cannot be modeled by a single distribution. We can sample from a mixture distribution by sampling from the component distributions and then taking a weighted sum of the samples <span class="math inline">\(X = Y_1\)</span> with probability <span class="math inline">\(w_1\)</span>, <span class="math inline">\(X = Y_2\)</span> with probability <span class="math inline">\(w_2\)</span>, <span class="math inline">\(\ldots, X = Y_n\)</span> with probability <span class="math inline">\(w_n\)</span>.</p>
<p>To sample from a mixture distribution, we can use the following algorithm:</p>
<ol type="1">
<li>Sample from the discrete distribution <span class="math inline">\([w_1, w_2, \ldots, w_n]\)</span> to select a component distribution.</li>
<li>Sample from the selected component distribution.</li>
<li>Return the sample.</li>
</ol>
<p>Note that this is not the same as constructing a linear combination of the component distributions. For example, if <span class="math inline">\(X_1 \sim N(\mu_1, \sigma_1^2)\)</span> and <span class="math inline">\(X_2 \sim N(\mu_2, \sigma_2^2)\)</span> are independent, then <span class="math inline">\(w_1 X_1 + w_2 X_2\)</span> is is a normal distribution with mean <span class="math inline">\(w_1 \mu_1 + w_2 \mu_2\)</span> and variance <span class="math inline">\(w_1^2 \sigma_1^2 + w_2^2 \sigma_2^2\)</span>. This is not the same as a mixture of two normal distributions.</p>
<div id="6bf27ceb" class="cell" data-execution_count="2">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="sampling_files/figure-html/cell-3-output-1.png" width="758" height="758" class="figure-img"></p>
</figure>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./rng.html" class="pagination-link" aria-label="Random Number Generators">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Random Number Generators</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./accept_reject.html" class="pagination-link" aria-label="Rejection Sampling">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Rejection Sampling</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>